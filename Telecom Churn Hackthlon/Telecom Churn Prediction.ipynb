{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc3c62c",
   "metadata": {},
   "source": [
    "# Telecom Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a233a4",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "Welcome to the case study module on Telecom Churn Prediction!\n",
    "\n",
    " \n",
    "\n",
    "In the telecommunication industry, customers tend to change operators if not provided with attractive schemes and offers. It is very important for any telecom operator to prevent the present customers from churning to other operators. As a data scientist, your task in this case study would be to build an ML model which can predict if the customer will churn or not in a particular month based on the past data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd019e",
   "metadata": {},
   "source": [
    "#### Objectives\n",
    "\n",
    "The main goal of the case study is to build ML models to predict churn. The predictive model that you’re going to build will the following purposes:\n",
    "\n",
    "It will be used to predict whether a high-value customer will churn or not, in near future (i.e. churn phase). By knowing this, the company can take action steps such as providing special plans, discounts on recharge etc.\n",
    "\n",
    "It will be used to identify important variables that are strong predictors of churn. These variables may also indicate why customers choose to switch to other networks.\n",
    "\n",
    "Even though overall accuracy will be your primary evaluation metric, you should also mention other metrics like precision, recall, etc. for the different models that can be used for evaluation purposes based on different business objectives. For example, in this problem statement, one business goal can be to build an ML model that identifies customers who'll definitely churn with more accuracy as compared to the ones who'll not churn. Make sure you mention which metric can be used in such scenarios.\n",
    "\n",
    " Recommend strategies to manage customer churn based on your observations.\n",
    "\n",
    " \n",
    "\n",
    "Note that it's highly likely that you'll need to build multiple models to fulfil the objectives mentioned in Points 1 and 2.  Since here, you have a large number of attributes, and thus you should try using a dimensionality reduction technique such as PCA and then build a predictive model. After PCA, you can use any classification model. \n",
    "\n",
    " \n",
    "\n",
    "The above model will only be able to achieve one of the two goals - to predict customers who will churn. You can’t use the above model to identify the important features for churn. That’s because PCA usually creates components that are not easy to interpret.\n",
    "\n",
    " \n",
    "\n",
    "Therefore, build another model with the main objective of identifying important predictor attributes which help the business understand indicators of churn. A good choice to identify important variables is a logistic regression model or a model from the tree family. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12584236",
   "metadata": {},
   "source": [
    "# Steps\n",
    "In the competition link, check the Code tab for the Starter Notebook that you can use as a reference for this entire case study. Some of the steps that you can use are as follows:\n",
    "\n",
    "#### Data Understanding, Preparation, and Pre-Processing :\n",
    "Data understanding, identification of potentially useful and non-useful attributes and variable importance and impact estimation\n",
    "Data preparation, performing data cleaning, missing values imputation, outlier removal, and column level standardization (for e.g., date, etc.) into one format\n",
    " \n",
    "#### Exploratory Data Analysis :\n",
    "Performing basic preliminary data analysis including finding the correlation between variables and scatter plots to identify relationships between variables\n",
    "Performing advanced data analysis, including plotting relevant heatmaps, histograms, and basic clustering to find patterns in the data\n",
    " \n",
    "#### Feature Engineering and Variable Transformation :\n",
    "Feature engineering and performing one or more methods on attributes that can lead to the creation of a new potentially useful variable; for e.g., day from the date\n",
    "Variable transformation and applying categorical variable transformations to turn into numerical data and numerical variable transformations to scale data\n",
    " \n",
    "#### Model Selection, Model Building, and  Prediction :\n",
    "Identifying the type of problem and making a list of decisive models from all available choices\n",
    "Choosing a training mechanism; for e.g., cross-validation, etc., and tuning hyperparameters of each model\n",
    "Testing each model on the respective model evaluation metric\n",
    "Choosing the best model based on the fit of the data set and output variable\n",
    "Using ensemble options to improve the efficacy based on the evaluation metric stated in the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48b337",
   "metadata": {},
   "source": [
    "## 1. Importing Dependencies, Data Loading and Understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e54687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc,roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811ce862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train and test data\n",
    "train_df=pd.read_csv(r'C:\\Users\\Rohit Chaudhary\\OneDrive\\Desktop\\Upgrad notes\\ML2\\Unsupervised learning\\Assigment Telecom Churn\\telecom-churn-case-study-hackathon-c37\\train.csv')\n",
    "test_df=pd.read_csv(r'C:\\Users\\Rohit Chaudhary\\OneDrive\\Desktop\\Upgrad notes\\ML2\\Unsupervised learning\\Assigment Telecom Churn\\telecom-churn-case-study-hackathon-c37\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff2f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df=pd.read_csv(r'C:\\Users\\Rohit Chaudhary\\OneDrive\\Desktop\\Upgrad notes\\ML2\\Unsupervised learning\\Assigment Telecom Churn\\telecom-churn-case-study-hackathon-c37\\solution.csv')\n",
    "y_test=y_test_df['churn_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc837ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69999, 172), (30000, 171))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e1e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_df['churn_probability']\n",
    "train_df=train_df.drop(['churn_probability'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8b17e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD1CAYAAABQtIIDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQwElEQVR4nO3df6ie5X3H8fenSeukndYfx+ASXRxm61RoO4NzFMbWjJnRsfiHwilshhIIiB0tDLa4f8b+COg/cxOmILUzuq4a3IqhxW4hTsaYxB5XVxut81BbPcSZtFpnB9rFfvfH+R725PjknOecxPNEz/sFD/d9f+/rus51Q+Rz7vu6n2OqCkmS3jfuCUiSTg8GgiQJMBAkSc1AkCQBBoIkqRkIkiQA1o57Ast1/vnn18aNG8c9DUl6V3niiSd+UFUTw869awNh48aNTE1NjXsakvSukuT7JzrnIyNJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSe1d+8W0d4uNu7427im8p3zvlk+NewrSe5Z3CJIkwECQJDUDQZIEGAiSpGYgSJKAEQMhyYeTPJjkO0meSfJrSc5Nsj/Jc709Z6D9zUmmkzyb5JqB+pVJnupztydJ189I8kDXDybZeMqvVJK0oFHvEP4K+HpVfQT4KPAMsAs4UFWbgAN9TJLLgEngcmArcEeSNT3OncBOYFN/tnZ9B/BqVV0K3AbcepLXJUlaokUDIclZwK8DdwNU1U+q6kfANmBPN9sDXNv724D7q+rNqnoemAauSnIhcFZVPVZVBdw7r8/cWA8CW+buHiRJK2OUO4RfAI4Cf5Pkm0m+kOSDwLqqegmgtxd0+/XAiwP9Z7q2vvfn14/rU1XHgNeA85Z1RZKkZRklENYCvwLcWVUfB/6Hfjx0AsN+s68F6gv1OX7gZGeSqSRTR48eXXjWkqQlGSUQZoCZqjrYxw8yGxAv92MgentkoP1FA/03AIe7vmFI/bg+SdYCZwOvzJ9IVd1VVZuravPExND/R7QkaZkWDYSq+i/gxSS/1KUtwNPAPmB717YDD/X+PmCy3xy6hNnF48f7sdLrSa7u9YEb5vWZG+s64JFeZ5AkrZBR/7jdHwJfSvIB4LvAZ5gNk71JdgAvANcDVNWhJHuZDY1jwE1V9VaPcyNwD3Am8HB/YHbB+r4k08zeGUye5HVJkpZopECoqieBzUNObTlB+93A7iH1KeCKIfU36ECRJI2H31SWJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktRGCoQk30vyVJInk0x17dwk+5M819tzBtrfnGQ6ybNJrhmoX9njTCe5PUm6fkaSB7p+MMnGU3ydkqRFLOUO4Ter6mNVtbmPdwEHqmoTcKCPSXIZMAlcDmwF7kiypvvcCewENvVna9d3AK9W1aXAbcCty78kSdJynMwjo23Ant7fA1w7UL+/qt6squeBaeCqJBcCZ1XVY1VVwL3z+syN9SCwZe7uQZK0MkYNhAL+KckTSXZ2bV1VvQTQ2wu6vh54caDvTNfW9/78+nF9quoY8Bpw3tIuRZJ0MtaO2O4TVXU4yQXA/iTfWaDtsN/sa4H6Qn2OH3g2jHYCXHzxxQvPWJK0JCPdIVTV4d4eAb4CXAW83I+B6O2Rbj4DXDTQfQNwuOsbhtSP65NkLXA28MqQedxVVZuravPExMQoU5ckjWjRQEjywSQ/O7cP/DbwbWAfsL2bbQce6v19wGS/OXQJs4vHj/djpdeTXN3rAzfM6zM31nXAI73OIElaIaM8MloHfKXXeNcCf1dVX0/yDWBvkh3AC8D1AFV1KMle4GngGHBTVb3VY90I3AOcCTzcH4C7gfuSTDN7ZzB5Cq5NkrQEiwZCVX0X+OiQ+g+BLSfosxvYPaQ+BVwxpP4GHSiSpPHwm8qSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIktrIgZBkTZJvJvlqH5+bZH+S53p7zkDbm5NMJ3k2yTUD9SuTPNXnbk+Srp+R5IGuH0yy8RReoyRpBEu5Q/gc8MzA8S7gQFVtAg70MUkuAyaBy4GtwB1J1nSfO4GdwKb+bO36DuDVqroUuA24dVlXI0latpECIckG4FPAFwbK24A9vb8HuHagfn9VvVlVzwPTwFVJLgTOqqrHqqqAe+f1mRvrQWDL3N2DJGlljHqH8JfAHwM/Haitq6qXAHp7QdfXAy8OtJvp2vren18/rk9VHQNeA84b9SIkSSdv0UBI8rvAkap6YsQxh/1mXwvUF+ozfy47k0wlmTp69OiI05EkjWKUO4RPAL+X5HvA/cAnk/wt8HI/BqK3R7r9DHDRQP8NwOGubxhSP65PkrXA2cAr8ydSVXdV1eaq2jwxMTHSBUqSRrNoIFTVzVW1oao2MrtY/EhV/T6wD9jezbYDD/X+PmCy3xy6hNnF48f7sdLrSa7u9YEb5vWZG+u6/hlvu0OQJL1z1p5E31uAvUl2AC8A1wNU1aEke4GngWPATVX1Vve5EbgHOBN4uD8AdwP3JZlm9s5g8iTmJUlahiUFQlU9Cjza+z8Etpyg3W5g95D6FHDFkPobdKBIksbDbypLkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWqLBkKSn0nyeJL/SHIoyZ93/dwk+5M819tzBvrcnGQ6ybNJrhmoX5nkqT53e5J0/YwkD3T9YJKN78C1SpIWMModwpvAJ6vqo8DHgK1JrgZ2AQeqahNwoI9JchkwCVwObAXuSLKmx7oT2Als6s/Wru8AXq2qS4HbgFtP/tIkSUuxaCDUrB/34fv7U8A2YE/X9wDX9v424P6qerOqngemgauSXAicVVWPVVUB987rMzfWg8CWubsHSdLKGGkNIcmaJE8CR4D9VXUQWFdVLwH09oJuvh54caD7TNfW9/78+nF9quoY8Bpw3jKuR5K0TCMFQlW9VVUfAzYw+9v+FQs0H/abfS1QX6jP8QMnO5NMJZk6evToIrOWJC3Fkt4yqqofAY8y++z/5X4MRG+PdLMZ4KKBbhuAw13fMKR+XJ8ka4GzgVeG/Py7qmpzVW2emJhYytQlSYsY5S2jiSQf7v0zgd8CvgPsA7Z3s+3AQ72/D5jsN4cuYXbx+PF+rPR6kqt7feCGeX3mxroOeKTXGSRJK2TtCG0uBPb0m0LvA/ZW1VeTPAbsTbIDeAG4HqCqDiXZCzwNHANuqqq3eqwbgXuAM4GH+wNwN3Bfkmlm7wwmT8XFSZJGt2ggVNW3gI8Pqf8Q2HKCPruB3UPqU8Db1h+q6g06UCRJ4+E3lSVJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAktUUDIclFSf45yTNJDiX5XNfPTbI/yXO9PWegz81JppM8m+SagfqVSZ7qc7cnSdfPSPJA1w8m2fgOXKskaQGj3CEcA/6oqn4ZuBq4KcllwC7gQFVtAg70MX1uErgc2ArckWRNj3UnsBPY1J+tXd8BvFpVlwK3AbeegmuTJC3BooFQVS9V1b/3/uvAM8B6YBuwp5vtAa7t/W3A/VX1ZlU9D0wDVyW5EDirqh6rqgLunddnbqwHgS1zdw+SpJWxpDWEfpTzceAgsK6qXoLZ0AAu6GbrgRcHus10bX3vz68f16eqjgGvAectZW6SpJMzciAk+RDw98Dnq+q/F2o6pFYL1BfqM38OO5NMJZk6evToYlOWJC3BSIGQ5P3MhsGXquofuvxyPwait0e6PgNcNNB9A3C46xuG1I/rk2QtcDbwyvx5VNVdVbW5qjZPTEyMMnVJ0ohGecsowN3AM1X1FwOn9gHbe3878NBAfbLfHLqE2cXjx/ux0utJru4xb5jXZ26s64BHep1BkrRC1o7Q5hPAHwBPJXmya38K3ALsTbIDeAG4HqCqDiXZCzzN7BtKN1XVW93vRuAe4Ezg4f7AbODcl2Sa2TuDyZO7LEnSUi0aCFX1rwx/xg+w5QR9dgO7h9SngCuG1N+gA0WSNB5+U1mSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUls0EJJ8McmRJN8eqJ2bZH+S53p7zsC5m5NMJ3k2yTUD9SuTPNXnbk+Srp+R5IGuH0yy8RRfoyRpBKPcIdwDbJ1X2wUcqKpNwIE+JsllwCRwefe5I8ma7nMnsBPY1J+5MXcAr1bVpcBtwK3LvRhJ0vItGghV9S/AK/PK24A9vb8HuHagfn9VvVlVzwPTwFVJLgTOqqrHqqqAe+f1mRvrQWDL3N2DJGnlLHcNYV1VvQTQ2wu6vh54caDdTNfW9/78+nF9quoY8Bpw3rAfmmRnkqkkU0ePHl3m1CVJw5zqReVhv9nXAvWF+ry9WHVXVW2uqs0TExPLnKIkaZjlBsLL/RiI3h7p+gxw0UC7DcDhrm8YUj+uT5K1wNm8/RGVJOkdttxA2Ads7/3twEMD9cl+c+gSZhePH+/HSq8nubrXB26Y12durOuAR3qdQZK0gtYu1iDJl4HfAM5PMgP8GXALsDfJDuAF4HqAqjqUZC/wNHAMuKmq3uqhbmT2jaUzgYf7A3A3cF+SaWbvDCZPyZVJkpZk0UCoqk+f4NSWE7TfDeweUp8CrhhSf4MOFEnS+PhNZUkSYCBIkpqBIEkCDARJUlt0UVnSe9PGXV8b9xTeU753y6fGPYWT5h2CJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAGnUSAk2Zrk2STTSXaNez6StNqcFoGQZA3w18DvAJcBn05y2XhnJUmry2kRCMBVwHRVfbeqfgLcD2wb85wkaVVZO+4JtPXAiwPHM8Cvzm+UZCewsw9/nOTZFZjbanE+8INxT2IxuXXcM9AY+G/z1Pr5E504XQIhQ2r1tkLVXcBd7/x0Vp8kU1W1edzzkObz3+bKOV0eGc0AFw0cbwAOj2kukrQqnS6B8A1gU5JLknwAmAT2jXlOkrSqnBaPjKrqWJLPAv8IrAG+WFWHxjyt1cZHcTpd+W9zhaTqbY/qJUmr0OnyyEiSNGYGgiQJMBAkSe20WFTWykryEWa/Cb6e2e97HAb2VdUzY52YpLHyDmGVSfInzP5pkACPM/vKb4Av+0cFdTpL8plxz+G9zreMVpkk/wlcXlX/O6/+AeBQVW0az8ykhSV5oaouHvc83st8ZLT6/BT4OeD78+oX9jlpbJJ860SngHUrOZfVyEBYfT4PHEjyHP//BwUvBi4FPjuuSUltHXAN8Oq8eoB/W/nprC4GwipTVV9P8ovM/snx9cz+hzYDfKOq3hrr5CT4KvChqnpy/okkj674bFYZ1xAkSYBvGUmSmoEgSQIMBElSMxAkSYCBIElq/wf4Vqkpsj/aZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84cfba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn percentage in training data is:  10.19 %\n"
     ]
    }
   ],
   "source": [
    "print('Churn percentage in training data is: ',round(100*y_train.value_counts()[1]/y_train.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0314fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_data=pd.concat([train_df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c25f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 171)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45756841",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.18</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.38</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.03</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.93</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>9.13</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.21</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.14</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   87.009    7.527        48.58       124.38         1.29         32.24   \n",
       "1  122.787   42.953         0.00         0.00         0.00          0.00   \n",
       "2  103.176    0.000         0.53        15.93         0.00         53.99   \n",
       "3  205.260  111.095         7.26        16.01         0.00         68.76   \n",
       "4  128.191  101.565        21.28         4.83         6.13         56.99   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         96.68          2.33           0.00            0.0            0.0   \n",
       "1         25.99         30.89           0.00            0.0            0.0   \n",
       "2         82.05          0.00           0.00            0.0            0.0   \n",
       "3         78.48         50.23           0.00            0.0            0.0   \n",
       "4         38.11          9.63          53.64            0.0            0.0   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00            0.0           0.00              2.23   \n",
       "1           0.00            0.0           0.00              0.00   \n",
       "2           0.00            0.0           0.00              0.53   \n",
       "3           0.00            0.0           1.63              6.99   \n",
       "4          15.73            0.0           0.00             10.16   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0              0.00              0.28              5.29             16.04   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             12.98              0.00             24.11              0.00   \n",
       "3              3.94              0.00             37.91             44.89   \n",
       "4              4.83              6.13             36.74             19.88   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              2.33              0.00              0.00              0.00   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             23.63              0.00              0.00              0.00   \n",
       "4              4.61             11.99              1.23              5.01   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0              0.00              0.00              0.00          7.53   \n",
       "1              0.00             22.01             29.79          0.00   \n",
       "2              2.14              0.00              0.00         24.64   \n",
       "3              0.00              0.00              8.03         44.91   \n",
       "4              0.00              9.85              0.00         58.91   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         16.04          2.61             46.34            124.38   \n",
       "1          0.00          0.00              0.00              0.00   \n",
       "2         12.98          0.00              0.00              2.94   \n",
       "3         48.84         23.63              0.26             12.06   \n",
       "4         25.94         15.76              0.00              0.00   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              1.01             18.75             80.61               0.0   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2              0.00             28.94             82.05               0.0   \n",
       "3              0.00             15.33             25.93               4.6   \n",
       "4              0.00              4.35              0.00               0.0   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0              0.00               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.56               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         65.09        204.99   \n",
       "1               0.0               0.0          0.00          0.00   \n",
       "2               0.0               0.0         28.94         84.99   \n",
       "3               0.0               0.0         16.16         37.99   \n",
       "4               0.0               0.0          4.35          0.00   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0          1.01           0.0           0.0           0.0          8.20   \n",
       "1          0.00           0.0           0.0           0.0          0.00   \n",
       "2          0.00           0.0           0.0           0.0          2.89   \n",
       "3          4.60           0.0           0.0           0.0         14.95   \n",
       "4          0.00           0.0           0.0           0.0          0.00   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.63          0.00         0.38          0.0          0.0   \n",
       "1         30.73         31.66         0.00          0.0          0.0   \n",
       "2          1.38          0.00         0.00          0.0          0.0   \n",
       "3          9.13         25.61         0.00          0.0          0.0   \n",
       "4         17.00          0.00         0.00          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           81.21          221.68            3.63              2.43   \n",
       "1            0.00           30.73           31.66              1.68   \n",
       "2           56.49           99.36            0.00              4.51   \n",
       "3           76.03           95.98           53.84             24.98   \n",
       "4           63.26           42.94           15.76              5.44   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0              3.68              7.79              0.83             21.08   \n",
       "1             19.09             10.53              1.41             18.68   \n",
       "2              6.16              6.49             89.86             25.18   \n",
       "3              4.84             23.88             53.99             44.23   \n",
       "4              1.39              2.66             10.58              4.33   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0             16.91              0.00              0.00              0.00   \n",
       "1             11.09              0.35              1.66              3.40   \n",
       "2             23.51              0.00              0.00              0.00   \n",
       "3             57.14              7.23              0.81              0.00   \n",
       "4             19.49              5.51              3.63              6.14   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0          3.26         24.76         24.71              0.00   \n",
       "1          3.44         39.44         25.03              0.00   \n",
       "2         94.38         31.34         30.01             11.69   \n",
       "3         86.21         49.89         81.03              0.00   \n",
       "4         21.54          9.36         28.31              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              7.61              0.21              7.46             19.96   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00             18.21              2.48   \n",
       "3              0.00              0.00              8.89              0.28   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0             14.96               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              6.38               0.0               0.0               0.0   \n",
       "3              2.81               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          7.46   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0         29.91   \n",
       "3               0.0               0.0               0.0          8.89   \n",
       "4               0.0               0.0               0.0          0.00   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0         27.58         15.18           11.84           53.04           40.56   \n",
       "1          0.00          0.00            3.44           39.44           25.04   \n",
       "2          2.48          6.38          124.29           33.83           36.64   \n",
       "3          0.28          2.81           95.11           50.18           83.84   \n",
       "4          0.00          0.00           21.54            9.36           28.31   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0           0.0           0.0          0.66           0.0           0.0   \n",
       "1           0.0           0.0          0.01           0.0           0.0   \n",
       "2           0.0           0.0          0.00           0.0           0.0   \n",
       "3           0.0           0.0          0.00           0.0           0.0   \n",
       "4           0.0           0.0          0.00           0.0           0.0   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0           0.0         1.11         0.69         0.00                 3   \n",
       "1           0.0         0.00         0.00         0.00                 3   \n",
       "2           0.0         0.00         0.00         0.25                 2   \n",
       "3           0.0         0.00         0.00         0.00                 2   \n",
       "4           0.0         0.00         0.00         0.00                13   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 2                 2                77                65   \n",
       "1                 4                 5                 0               145   \n",
       "2                 4                 2                70               120   \n",
       "3                 4                 3               160               240   \n",
       "4                10                 8               290               136   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                10              65              65              10   \n",
       "1                50               0             145              50   \n",
       "2                 0              70              70               0   \n",
       "3               130             110             110              50   \n",
       "4               122              50              41              30   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/22/2014           7/10/2014           8/24/2014   \n",
       "1           6/12/2014           7/10/2014           8/26/2014   \n",
       "2           6/11/2014           7/22/2014           8/24/2014   \n",
       "3           6/15/2014           7/21/2014           8/25/2014   \n",
       "4           6/25/2014           7/26/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  65                  65                   0   \n",
       "1                   0                   0                   0   \n",
       "2                  70                  50                   0   \n",
       "3                 110                 110                  50   \n",
       "4                  25                  10                  30   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                 7/8/2014                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                6/25/2014                7/23/2014                8/20/2014   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                1.0                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                7.0                7.0                6.0             25.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1            145.0              NaN              NaN              0.0   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4             41.0             25.0              7.0              6.0   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              1.0              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              6.0              0.0              1.0              0.0   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN               145.0                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4               175.0               191.0               142.0        390.8   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "1       352.91         0.00          0.0         3.96          0.0        NaN   \n",
       "2         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "3         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "4       308.89       213.47          0.0         0.00          0.0        0.0   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1     122.07        NaN        NaN     122.08        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4      35.00        0.0        0.0      35.12        0.0               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               0.0               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               0.0               0.0             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            7            6            6             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             1             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            1            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN        NaN        NaN  1958         0.0         0.0         0.0  \n",
       "1        NaN        1.0        NaN   710         0.0         0.0         0.0  \n",
       "2        NaN        NaN        NaN   882         0.0         0.0         0.0  \n",
       "3        NaN        NaN        NaN   982         0.0         0.0         0.0  \n",
       "4        1.0        1.0        1.0   647         0.0         0.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11378f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets divide data into categorical and numeric time, thereafter we will check data in detail\n",
    "#Numeric columns\n",
    "num_col=list(tel_data.select_dtypes(['float64','int64','float32','int32']).columns)\n",
    "len(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff715d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.18</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.38</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.03</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.93</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>9.13</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.21</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.14</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou   arpu_6  \\\n",
       "0   0        109             0.0             0.0             0.0   31.277   \n",
       "1   1        109             0.0             0.0             0.0    0.000   \n",
       "2   2        109             0.0             0.0             0.0   60.806   \n",
       "3   3        109             0.0             0.0             0.0  156.362   \n",
       "4   4        109             0.0             0.0             0.0  240.708   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   87.009    7.527        48.58       124.38         1.29         32.24   \n",
       "1  122.787   42.953         0.00         0.00         0.00          0.00   \n",
       "2  103.176    0.000         0.53        15.93         0.00         53.99   \n",
       "3  205.260  111.095         7.26        16.01         0.00         68.76   \n",
       "4  128.191  101.565        21.28         4.83         6.13         56.99   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         96.68          2.33           0.00            0.0            0.0   \n",
       "1         25.99         30.89           0.00            0.0            0.0   \n",
       "2         82.05          0.00           0.00            0.0            0.0   \n",
       "3         78.48         50.23           0.00            0.0            0.0   \n",
       "4         38.11          9.63          53.64            0.0            0.0   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00            0.0           0.00              2.23   \n",
       "1           0.00            0.0           0.00              0.00   \n",
       "2           0.00            0.0           0.00              0.53   \n",
       "3           0.00            0.0           1.63              6.99   \n",
       "4          15.73            0.0           0.00             10.16   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0              0.00              0.28              5.29             16.04   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             12.98              0.00             24.11              0.00   \n",
       "3              3.94              0.00             37.91             44.89   \n",
       "4              4.83              6.13             36.74             19.88   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              2.33              0.00              0.00              0.00   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             23.63              0.00              0.00              0.00   \n",
       "4              4.61             11.99              1.23              5.01   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0              0.00              0.00              0.00          7.53   \n",
       "1              0.00             22.01             29.79          0.00   \n",
       "2              2.14              0.00              0.00         24.64   \n",
       "3              0.00              0.00              8.03         44.91   \n",
       "4              0.00              9.85              0.00         58.91   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         16.04          2.61             46.34            124.38   \n",
       "1          0.00          0.00              0.00              0.00   \n",
       "2         12.98          0.00              0.00              2.94   \n",
       "3         48.84         23.63              0.26             12.06   \n",
       "4         25.94         15.76              0.00              0.00   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              1.01             18.75             80.61               0.0   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2              0.00             28.94             82.05               0.0   \n",
       "3              0.00             15.33             25.93               4.6   \n",
       "4              0.00              4.35              0.00               0.0   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0              0.00               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.56               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         65.09        204.99   \n",
       "1               0.0               0.0          0.00          0.00   \n",
       "2               0.0               0.0         28.94         84.99   \n",
       "3               0.0               0.0         16.16         37.99   \n",
       "4               0.0               0.0          4.35          0.00   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0          1.01           0.0           0.0           0.0          8.20   \n",
       "1          0.00           0.0           0.0           0.0          0.00   \n",
       "2          0.00           0.0           0.0           0.0          2.89   \n",
       "3          4.60           0.0           0.0           0.0         14.95   \n",
       "4          0.00           0.0           0.0           0.0          0.00   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.63          0.00         0.38          0.0          0.0   \n",
       "1         30.73         31.66         0.00          0.0          0.0   \n",
       "2          1.38          0.00         0.00          0.0          0.0   \n",
       "3          9.13         25.61         0.00          0.0          0.0   \n",
       "4         17.00          0.00         0.00          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           81.21          221.68            3.63              2.43   \n",
       "1            0.00           30.73           31.66              1.68   \n",
       "2           56.49           99.36            0.00              4.51   \n",
       "3           76.03           95.98           53.84             24.98   \n",
       "4           63.26           42.94           15.76              5.44   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0              3.68              7.79              0.83             21.08   \n",
       "1             19.09             10.53              1.41             18.68   \n",
       "2              6.16              6.49             89.86             25.18   \n",
       "3              4.84             23.88             53.99             44.23   \n",
       "4              1.39              2.66             10.58              4.33   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0             16.91              0.00              0.00              0.00   \n",
       "1             11.09              0.35              1.66              3.40   \n",
       "2             23.51              0.00              0.00              0.00   \n",
       "3             57.14              7.23              0.81              0.00   \n",
       "4             19.49              5.51              3.63              6.14   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0          3.26         24.76         24.71              0.00   \n",
       "1          3.44         39.44         25.03              0.00   \n",
       "2         94.38         31.34         30.01             11.69   \n",
       "3         86.21         49.89         81.03              0.00   \n",
       "4         21.54          9.36         28.31              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              7.61              0.21              7.46             19.96   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00             18.21              2.48   \n",
       "3              0.00              0.00              8.89              0.28   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0             14.96               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              6.38               0.0               0.0               0.0   \n",
       "3              2.81               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          7.46   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0         29.91   \n",
       "3               0.0               0.0               0.0          8.89   \n",
       "4               0.0               0.0               0.0          0.00   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0         27.58         15.18           11.84           53.04           40.56   \n",
       "1          0.00          0.00            3.44           39.44           25.04   \n",
       "2          2.48          6.38          124.29           33.83           36.64   \n",
       "3          0.28          2.81           95.11           50.18           83.84   \n",
       "4          0.00          0.00           21.54            9.36           28.31   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0           0.0           0.0          0.66           0.0           0.0   \n",
       "1           0.0           0.0          0.01           0.0           0.0   \n",
       "2           0.0           0.0          0.00           0.0           0.0   \n",
       "3           0.0           0.0          0.00           0.0           0.0   \n",
       "4           0.0           0.0          0.00           0.0           0.0   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0           0.0         1.11         0.69         0.00                 3   \n",
       "1           0.0         0.00         0.00         0.00                 3   \n",
       "2           0.0         0.00         0.00         0.25                 2   \n",
       "3           0.0         0.00         0.00         0.00                 2   \n",
       "4           0.0         0.00         0.00         0.00                13   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 2                 2                77                65   \n",
       "1                 4                 5                 0               145   \n",
       "2                 4                 2                70               120   \n",
       "3                 4                 3               160               240   \n",
       "4                10                 8               290               136   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                10              65              65              10   \n",
       "1                50               0             145              50   \n",
       "2                 0              70              70               0   \n",
       "3               130             110             110              50   \n",
       "4               122              50              41              30   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  65                  65                   0   \n",
       "1                   0                   0                   0   \n",
       "2                  70                  50                   0   \n",
       "3                 110                 110                  50   \n",
       "4                  25                  10                  30   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                1.0                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                7.0                7.0                6.0             25.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1            145.0              NaN              NaN              0.0   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4             41.0             25.0              7.0              6.0   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              1.0              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              6.0              0.0              1.0              0.0   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN               145.0                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4               175.0               191.0               142.0        390.8   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "1       352.91         0.00          0.0         3.96          0.0        NaN   \n",
       "2         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "3         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "4       308.89       213.47          0.0         0.00          0.0        0.0   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1     122.07        NaN        NaN     122.08        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4      35.00        0.0        0.0      35.12        0.0               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               0.0               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               0.0               0.0             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            7            6            6             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             1             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            1            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN        NaN        NaN  1958         0.0         0.0         0.0  \n",
       "1        NaN        1.0        NaN   710         0.0         0.0         0.0  \n",
       "2        NaN        NaN        NaN   882         0.0         0.0         0.0  \n",
       "3        NaN        NaN        NaN   982         0.0         0.0         0.0  \n",
       "4        1.0        1.0        1.0   647         0.0         0.0         0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data[num_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d79b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical columns\n",
    "cat_col=list(tel_data.select_dtypes(['object']).columns)\n",
    "len(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df599c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/22/2014           7/10/2014           8/24/2014   \n",
       "1           6/12/2014           7/10/2014           8/26/2014   \n",
       "2           6/11/2014           7/22/2014           8/24/2014   \n",
       "3           6/15/2014           7/21/2014           8/25/2014   \n",
       "4           6/25/2014           7/26/2014           8/30/2014   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \n",
       "0                      NaN                      NaN                      NaN  \n",
       "1                      NaN                 7/8/2014                      NaN  \n",
       "2                      NaN                      NaN                      NaN  \n",
       "3                      NaN                      NaN                      NaN  \n",
       "4                6/25/2014                7/23/2014                8/20/2014  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data[cat_col].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72228a",
   "metadata": {},
   "source": [
    "All the columns with date are with data type as object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d79c68",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Data Visulization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19de577",
   "metadata": {},
   "source": [
    "#### 2.1 Missing value Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733c031f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>circle_id</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_6</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_7</th>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_8</th>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_6</th>\n",
       "      <td>74.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_7</th>\n",
       "      <td>74.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_8</th>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aon</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Null %\n",
       "id                          0.00\n",
       "circle_id                   0.00\n",
       "loc_og_t2o_mou              1.02\n",
       "std_og_t2o_mou              1.02\n",
       "loc_ic_t2o_mou              1.02\n",
       "last_date_of_month_6        0.00\n",
       "last_date_of_month_7        0.60\n",
       "last_date_of_month_8        1.10\n",
       "arpu_6                      0.00\n",
       "arpu_7                      0.00\n",
       "arpu_8                      0.00\n",
       "onnet_mou_6                 3.94\n",
       "onnet_mou_7                 3.86\n",
       "onnet_mou_8                 5.38\n",
       "offnet_mou_6                3.94\n",
       "offnet_mou_7                3.86\n",
       "offnet_mou_8                5.38\n",
       "roam_ic_mou_6               3.94\n",
       "roam_ic_mou_7               3.86\n",
       "roam_ic_mou_8               5.38\n",
       "roam_og_mou_6               3.94\n",
       "roam_og_mou_7               3.86\n",
       "roam_og_mou_8               5.38\n",
       "loc_og_t2t_mou_6            3.94\n",
       "loc_og_t2t_mou_7            3.86\n",
       "loc_og_t2t_mou_8            5.38\n",
       "loc_og_t2m_mou_6            3.94\n",
       "loc_og_t2m_mou_7            3.86\n",
       "loc_og_t2m_mou_8            5.38\n",
       "loc_og_t2f_mou_6            3.94\n",
       "loc_og_t2f_mou_7            3.86\n",
       "loc_og_t2f_mou_8            5.38\n",
       "loc_og_t2c_mou_6            3.94\n",
       "loc_og_t2c_mou_7            3.86\n",
       "loc_og_t2c_mou_8            5.38\n",
       "loc_og_mou_6                3.94\n",
       "loc_og_mou_7                3.86\n",
       "loc_og_mou_8                5.38\n",
       "std_og_t2t_mou_6            3.94\n",
       "std_og_t2t_mou_7            3.86\n",
       "std_og_t2t_mou_8            5.38\n",
       "std_og_t2m_mou_6            3.94\n",
       "std_og_t2m_mou_7            3.86\n",
       "std_og_t2m_mou_8            5.38\n",
       "std_og_t2f_mou_6            3.94\n",
       "std_og_t2f_mou_7            3.86\n",
       "std_og_t2f_mou_8            5.38\n",
       "std_og_t2c_mou_6            3.94\n",
       "std_og_t2c_mou_7            3.86\n",
       "std_og_t2c_mou_8            5.38\n",
       "std_og_mou_6                3.94\n",
       "std_og_mou_7                3.86\n",
       "std_og_mou_8                5.38\n",
       "isd_og_mou_6                3.94\n",
       "isd_og_mou_7                3.86\n",
       "isd_og_mou_8                5.38\n",
       "spl_og_mou_6                3.94\n",
       "spl_og_mou_7                3.86\n",
       "spl_og_mou_8                5.38\n",
       "og_others_6                 3.94\n",
       "og_others_7                 3.86\n",
       "og_others_8                 5.38\n",
       "total_og_mou_6              0.00\n",
       "total_og_mou_7              0.00\n",
       "total_og_mou_8              0.00\n",
       "loc_ic_t2t_mou_6            3.94\n",
       "loc_ic_t2t_mou_7            3.86\n",
       "loc_ic_t2t_mou_8            5.38\n",
       "loc_ic_t2m_mou_6            3.94\n",
       "loc_ic_t2m_mou_7            3.86\n",
       "loc_ic_t2m_mou_8            5.38\n",
       "loc_ic_t2f_mou_6            3.94\n",
       "loc_ic_t2f_mou_7            3.86\n",
       "loc_ic_t2f_mou_8            5.38\n",
       "loc_ic_mou_6                3.94\n",
       "loc_ic_mou_7                3.86\n",
       "loc_ic_mou_8                5.38\n",
       "std_ic_t2t_mou_6            3.94\n",
       "std_ic_t2t_mou_7            3.86\n",
       "std_ic_t2t_mou_8            5.38\n",
       "std_ic_t2m_mou_6            3.94\n",
       "std_ic_t2m_mou_7            3.86\n",
       "std_ic_t2m_mou_8            5.38\n",
       "std_ic_t2f_mou_6            3.94\n",
       "std_ic_t2f_mou_7            3.86\n",
       "std_ic_t2f_mou_8            5.38\n",
       "std_ic_t2o_mou_6            3.94\n",
       "std_ic_t2o_mou_7            3.86\n",
       "std_ic_t2o_mou_8            5.38\n",
       "std_ic_mou_6                3.94\n",
       "std_ic_mou_7                3.86\n",
       "std_ic_mou_8                5.38\n",
       "total_ic_mou_6              0.00\n",
       "total_ic_mou_7              0.00\n",
       "total_ic_mou_8              0.00\n",
       "spl_ic_mou_6                3.94\n",
       "spl_ic_mou_7                3.86\n",
       "spl_ic_mou_8                5.38\n",
       "isd_ic_mou_6                3.94\n",
       "isd_ic_mou_7                3.86\n",
       "isd_ic_mou_8                5.38\n",
       "ic_others_6                 3.94\n",
       "ic_others_7                 3.86\n",
       "ic_others_8                 5.38\n",
       "total_rech_num_6            0.00\n",
       "total_rech_num_7            0.00\n",
       "total_rech_num_8            0.00\n",
       "total_rech_amt_6            0.00\n",
       "total_rech_amt_7            0.00\n",
       "total_rech_amt_8            0.00\n",
       "max_rech_amt_6              0.00\n",
       "max_rech_amt_7              0.00\n",
       "max_rech_amt_8              0.00\n",
       "date_of_last_rech_6         1.61\n",
       "date_of_last_rech_7         1.77\n",
       "date_of_last_rech_8         3.62\n",
       "last_day_rch_amt_6          0.00\n",
       "last_day_rch_amt_7          0.00\n",
       "last_day_rch_amt_8          0.00\n",
       "date_of_last_rech_data_6   74.85\n",
       "date_of_last_rech_data_7   74.43\n",
       "date_of_last_rech_data_8   73.66\n",
       "total_rech_data_6          74.85\n",
       "total_rech_data_7          74.43\n",
       "total_rech_data_8          73.66\n",
       "max_rech_data_6            74.85\n",
       "max_rech_data_7            74.43\n",
       "max_rech_data_8            73.66\n",
       "count_rech_2g_6            74.85\n",
       "count_rech_2g_7            74.43\n",
       "count_rech_2g_8            73.66\n",
       "count_rech_3g_6            74.85\n",
       "count_rech_3g_7            74.43\n",
       "count_rech_3g_8            73.66\n",
       "av_rech_amt_data_6         74.85\n",
       "av_rech_amt_data_7         74.43\n",
       "av_rech_amt_data_8         73.66\n",
       "vol_2g_mb_6                 0.00\n",
       "vol_2g_mb_7                 0.00\n",
       "vol_2g_mb_8                 0.00\n",
       "vol_3g_mb_6                 0.00\n",
       "vol_3g_mb_7                 0.00\n",
       "vol_3g_mb_8                 0.00\n",
       "arpu_3g_6                  74.85\n",
       "arpu_3g_7                  74.43\n",
       "arpu_3g_8                  73.66\n",
       "arpu_2g_6                  74.85\n",
       "arpu_2g_7                  74.43\n",
       "arpu_2g_8                  73.66\n",
       "night_pck_user_6           74.85\n",
       "night_pck_user_7           74.43\n",
       "night_pck_user_8           73.66\n",
       "monthly_2g_6                0.00\n",
       "monthly_2g_7                0.00\n",
       "monthly_2g_8                0.00\n",
       "sachet_2g_6                 0.00\n",
       "sachet_2g_7                 0.00\n",
       "sachet_2g_8                 0.00\n",
       "monthly_3g_6                0.00\n",
       "monthly_3g_7                0.00\n",
       "monthly_3g_8                0.00\n",
       "sachet_3g_6                 0.00\n",
       "sachet_3g_7                 0.00\n",
       "sachet_3g_8                 0.00\n",
       "fb_user_6                  74.85\n",
       "fb_user_7                  74.43\n",
       "fb_user_8                  73.66\n",
       "aon                         0.00\n",
       "aug_vbc_3g                  0.00\n",
       "jul_vbc_3g                  0.00\n",
       "jun_vbc_3g                  0.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check missing value columns\n",
    "pd.DataFrame(round(100* tel_data.isnull().sum()/tel_data.shape[0],2), columns=['Null %'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecdf47",
   "metadata": {},
   "source": [
    "There are lot of columns with missing values more than 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942ba38",
   "metadata": {},
   "source": [
    "Lets drop columns with missing vales greater than 50% and for numeric values with median values and dates with mode values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c33692d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_null_value_col=[]\n",
    "for col in tel_data.columns:\n",
    "    if (tel_data[col].isnull().sum()/tel_data.shape[0])>0.5:\n",
    "        high_null_value_col.append(col)\n",
    "len(high_null_value_col)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d26f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove these columns from num_col and cat_col\n",
    "for col in high_null_value_col:\n",
    "    if (tel_data[col].dtypes=='O'):\n",
    "        cat_col.remove(col)\n",
    "    else:\n",
    "        num_col.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47f4cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing numeric values\n",
    "for col in tel_data.columns:\n",
    "    if (tel_data[col].isnull().sum()/tel_data.shape[0])>0:\n",
    "        #dropping columns with missing value more than 50%\n",
    "        if (tel_data[col].isnull().sum()/tel_data.shape[0])>0.5:\n",
    "            tel_data=tel_data.drop([col], axis=1)\n",
    "            continue\n",
    "            # imputing median value for numeric data tyoe\n",
    "        elif (tel_data[col].dtypes=='int64') or (tel_data[col].dtypes=='float64'):\n",
    "            tel_data[col]= tel_data[col].fillna(tel_data[col].median())\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee89da",
   "metadata": {},
   "source": [
    "In order to treat missing values in dates. Lets check effect of null values in date_of_last_rech_7',date_of_last_rech_8',date_of_last_rech_6' on churn rate in training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2b8b814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4054, 172)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['churn_probability']=y_train\n",
    "Null_effect_on_churn=train_df[(train_df['date_of_last_rech_6'].isnull()==True) |\\\n",
    "                              (train_df['date_of_last_rech_7'].isnull()==True) |\\\n",
    "                              (train_df['date_of_last_rech_8'].isnull()==True)]\n",
    "Null_effect_on_churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee6be630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Null_effect_on_churn['churn_probability'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd5316e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn percentage in training data in case of null values in variables is 'date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8' is:  41.61 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Churn percentage in training data in case of null values in variables is 'date_of_last_rech_6',\\\n",
    "'date_of_last_rech_7','date_of_last_rech_8' is: \",round(100*Null_effect_on_churn['churn_probability']\\\n",
    "                                                .value_counts()[1]/Null_effect_on_churn.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c6431",
   "metadata": {},
   "source": [
    "- Total churn rate in training data is 10.19 %, however as seen above churn rate is very high i.e. 41.61% among cases where there are null values in variables`'date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8'`, indicating in these cases there was no rechare done in these months.\n",
    "- `date_of_last_rech_data_6,date_of_last_rech_data_7,date_of_last_rech_data_8` were not considered for this purpose as upon there introduction churn rate was around 11% which is almost same as total churn rate in train data. Thus it was not impacting data much hence those variables has been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd845e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing first date of respective month i.e starting date of dataframe in 'date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8' \n",
    "#as we will be create new features with days since last recharge for all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b494561",
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_data['date_of_last_rech_6'].fillna(value='6/1/2014', inplace=True)\n",
    "tel_data['date_of_last_rech_7'].fillna(value='7/1/2014', inplace=True)\n",
    "tel_data['date_of_last_rech_8'].fillna(value='8/1/2014', inplace=True)\n",
    "tel_data['last_date_of_month_7'].fillna(tel_data['last_date_of_month_7'].value_counts().index[0], inplace=True)\n",
    "tel_data['last_date_of_month_8'].fillna(tel_data['last_date_of_month_8'].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eb6fa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d88e8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_col)+len(cat_col)==tel_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e576d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove 'id' from num_col and data\n",
    "num_col.remove('id')\n",
    "tel_data=tel_data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266460d9",
   "metadata": {},
   "source": [
    "#### 2.2 Unique value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1834d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou', 'loc_ic_t2o_mou', 'last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8', 'std_og_t2c_mou_6', 'std_og_t2c_mou_7', 'std_og_t2c_mou_8', 'std_ic_t2o_mou_6', 'std_ic_t2o_mou_7', 'std_ic_t2o_mou_8']\n"
     ]
    }
   ],
   "source": [
    "#Lets drop columns with only single unique value as these columns adds on information to model.\n",
    "single_Unique_value_col=[]\n",
    "for col in tel_data.columns:\n",
    "    if len(tel_data[col].unique())==1:\n",
    "        single_Unique_value_col.append(col)\n",
    "print(single_Unique_value_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7246f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109    99999\n",
      "Name: circle_id, dtype: int64\n",
      "0.0    99999\n",
      "Name: loc_og_t2o_mou, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_og_t2o_mou, dtype: int64\n",
      "0.0    99999\n",
      "Name: loc_ic_t2o_mou, dtype: int64\n",
      "6/30/2014    99999\n",
      "Name: last_date_of_month_6, dtype: int64\n",
      "7/31/2014    99999\n",
      "Name: last_date_of_month_7, dtype: int64\n",
      "8/31/2014    99999\n",
      "Name: last_date_of_month_8, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_og_t2c_mou_6, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_og_t2c_mou_7, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_og_t2c_mou_8, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_ic_t2o_mou_6, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_ic_t2o_mou_7, dtype: int64\n",
      "0.0    99999\n",
      "Name: std_ic_t2o_mou_8, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Lets check values in these columsn\n",
    "for i in single_Unique_value_col:\n",
    "    print(tel_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f26e0",
   "metadata": {},
   "source": [
    "We will remove all variables except 'last_date_of_month_6','last_date_of_month_7','last_date_of_month_8'. Will remove variables later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66a4fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['last_date_of_month_6','last_date_of_month_7','last_date_of_month_8']:\n",
    "    single_Unique_value_col.remove(i)\n",
    "tel_data=tel_data.drop(single_Unique_value_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35daa41e",
   "metadata": {},
   "source": [
    "All the varaibles were alo checked for before imputing missing values and it was seen maximun varaibles were having single value in them thus not adding any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9caa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in single_Unique_value_col:\n",
    "    if col in num_col:\n",
    "        num_col.remove(col)\n",
    "    else:\n",
    "        cat_col.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a740732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_col)+len(cat_col)==tel_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "689669ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 130)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b5def",
   "metadata": {},
   "source": [
    "####  2.2 Outliers treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6f0c73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlier%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arpu_6</th>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_7</th>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_8</th>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <td>12.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <td>12.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <td>12.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <td>10.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <td>10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <td>10.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <td>8.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <td>16.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <td>16.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <td>16.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <td>8.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <td>8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <td>8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <td>18.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <td>18.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <td>18.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <td>15.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <td>16.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <td>14.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <td>15.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <td>16.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <td>14.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <td>14.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <td>9.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <td>9.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <td>9.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <td>7.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <td>14.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <td>14.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <td>14.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <td>16.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <td>16.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <td>17.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <td>12.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <td>11.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <td>11.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aon</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Outlier%\n",
       "arpu_6                  5.75\n",
       "arpu_7                  5.79\n",
       "arpu_8                  5.59\n",
       "onnet_mou_6            12.26\n",
       "onnet_mou_7            12.63\n",
       "onnet_mou_8            12.67\n",
       "offnet_mou_6            8.89\n",
       "offnet_mou_7            9.25\n",
       "offnet_mou_8            9.44\n",
       "roam_ic_mou_6         100.00\n",
       "roam_ic_mou_7         100.00\n",
       "roam_ic_mou_8         100.00\n",
       "roam_og_mou_6         100.00\n",
       "roam_og_mou_7         100.00\n",
       "roam_og_mou_8         100.00\n",
       "loc_og_t2t_mou_6       10.84\n",
       "loc_og_t2t_mou_7       10.83\n",
       "loc_og_t2t_mou_8       10.94\n",
       "loc_og_t2m_mou_6        8.85\n",
       "loc_og_t2m_mou_7        8.83\n",
       "loc_og_t2m_mou_8        8.92\n",
       "loc_og_t2f_mou_6       16.17\n",
       "loc_og_t2f_mou_7       16.06\n",
       "loc_og_t2f_mou_8       16.16\n",
       "loc_og_t2c_mou_6      100.00\n",
       "loc_og_t2c_mou_7      100.00\n",
       "loc_og_t2c_mou_8      100.00\n",
       "loc_og_mou_6            8.81\n",
       "loc_og_mou_7            8.96\n",
       "loc_og_mou_8            8.93\n",
       "std_og_t2t_mou_6       18.22\n",
       "std_og_t2t_mou_7       18.29\n",
       "std_og_t2t_mou_8       18.54\n",
       "std_og_t2m_mou_6       15.55\n",
       "std_og_t2m_mou_7       15.72\n",
       "std_og_t2m_mou_8       16.05\n",
       "std_og_t2f_mou_6      100.00\n",
       "std_og_t2f_mou_7      100.00\n",
       "std_og_t2f_mou_8      100.00\n",
       "std_og_mou_6           14.69\n",
       "std_og_mou_7           14.95\n",
       "std_og_mou_8           15.22\n",
       "isd_og_mou_6          100.00\n",
       "isd_og_mou_7          100.00\n",
       "isd_og_mou_8          100.00\n",
       "spl_og_mou_6           16.31\n",
       "spl_og_mou_7           14.37\n",
       "spl_og_mou_8           14.14\n",
       "og_others_6           100.00\n",
       "og_others_7           100.00\n",
       "og_others_8           100.00\n",
       "total_og_mou_6          8.44\n",
       "total_og_mou_7          8.62\n",
       "total_og_mou_8          8.60\n",
       "loc_ic_t2t_mou_6        9.64\n",
       "loc_ic_t2t_mou_7        9.86\n",
       "loc_ic_t2t_mou_8        9.74\n",
       "loc_ic_t2m_mou_6        7.65\n",
       "loc_ic_t2m_mou_7        7.63\n",
       "loc_ic_t2m_mou_8        7.70\n",
       "loc_ic_t2f_mou_6       14.32\n",
       "loc_ic_t2f_mou_7       14.13\n",
       "loc_ic_t2f_mou_8       14.13\n",
       "loc_ic_mou_6            7.53\n",
       "loc_ic_mou_7            7.69\n",
       "loc_ic_mou_8            7.69\n",
       "std_ic_t2t_mou_6       16.69\n",
       "std_ic_t2t_mou_7       16.65\n",
       "std_ic_t2t_mou_8       17.07\n",
       "std_ic_t2m_mou_6       12.82\n",
       "std_ic_t2m_mou_7       12.80\n",
       "std_ic_t2m_mou_8       13.10\n",
       "std_ic_t2f_mou_6      100.00\n",
       "std_ic_t2f_mou_7      100.00\n",
       "std_ic_t2f_mou_8      100.00\n",
       "std_ic_mou_6           11.64\n",
       "std_ic_mou_7           11.49\n",
       "std_ic_mou_8           11.68\n",
       "total_ic_mou_6          6.95\n",
       "total_ic_mou_7          7.22\n",
       "total_ic_mou_8          7.11\n",
       "spl_ic_mou_6          100.00\n",
       "spl_ic_mou_7          100.00\n",
       "spl_ic_mou_8          100.00\n",
       "isd_ic_mou_6          100.00\n",
       "isd_ic_mou_7          100.00\n",
       "isd_ic_mou_8          100.00\n",
       "ic_others_6           100.00\n",
       "ic_others_7           100.00\n",
       "ic_others_8           100.00\n",
       "total_rech_num_6        7.30\n",
       "total_rech_num_7        5.14\n",
       "total_rech_num_8        7.37\n",
       "total_rech_amt_6        5.81\n",
       "total_rech_amt_7        6.01\n",
       "total_rech_amt_8        5.56\n",
       "max_rech_amt_6          4.36\n",
       "max_rech_amt_7          4.09\n",
       "max_rech_amt_8          3.65\n",
       "last_day_rch_amt_6      1.84\n",
       "last_day_rch_amt_7      1.84\n",
       "last_day_rch_amt_8      1.80\n",
       "vol_2g_mb_6           100.00\n",
       "vol_2g_mb_7           100.00\n",
       "vol_2g_mb_8           100.00\n",
       "vol_3g_mb_6           100.00\n",
       "vol_3g_mb_7           100.00\n",
       "vol_3g_mb_8           100.00\n",
       "monthly_2g_6          100.00\n",
       "monthly_2g_7          100.00\n",
       "monthly_2g_8          100.00\n",
       "sachet_2g_6           100.00\n",
       "sachet_2g_7           100.00\n",
       "sachet_2g_8           100.00\n",
       "monthly_3g_6          100.00\n",
       "monthly_3g_7          100.00\n",
       "monthly_3g_8          100.00\n",
       "sachet_3g_6           100.00\n",
       "sachet_3g_7           100.00\n",
       "sachet_3g_8           100.00\n",
       "aon                     0.12\n",
       "aug_vbc_3g            100.00\n",
       "jul_vbc_3g            100.00\n",
       "jun_vbc_3g            100.00"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check no. of outliers\n",
    "Outlier_data={}\n",
    "for col in num_col:\n",
    "    Q1= tel_data[col].quantile(0.25)\n",
    "    Q2= tel_data[col].quantile(0.75)\n",
    "    IQR=Q2-Q1\n",
    "    outliers=tel_data[(tel_data[col]<=(Q1-1.5*IQR)) |(tel_data[col]>=(Q2+1.5*IQR))]\n",
    "    Outlier_data[col]=round(100*outliers.shape[0]/tel_data.shape[0],2)\n",
    "    \n",
    "Outlier_per =pd.DataFrame([Outlier_data]).T\n",
    "Outlier_per.columns=['Outlier%']\n",
    "Outlier_per[Outlier_per['Outlier%']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3452d",
   "metadata": {},
   "source": [
    "We will not drop outliers as although statistically there are outliers but as per business these values may not be unexpected and thus cannot be called outliers by removing these datapoints we may lose important information. Therfore we will not remove these outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0101397",
   "metadata": {},
   "source": [
    "### 3. Data Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67d068",
   "metadata": {},
   "source": [
    "#### 3.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a41faa",
   "metadata": {},
   "source": [
    "%%time\n",
    "plt.subplots(figsize=[15,250])\n",
    "k=1\n",
    "for col in num_col:\n",
    "    plt.subplot(int(len(num_col)/2)+1,4,k)\n",
    "    sns.distplot(tel_data[col])\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03025724",
   "metadata": {},
   "source": [
    "As seen above maximum variables are having values close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58f5d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,40))\n",
    "#sns.boxplot(x='value',y='variable', data=pd.melt(tel_data[num_col]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd0295",
   "metadata": {},
   "source": [
    "#### 2.2 Bivariate Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f41ecf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Variation of features with churning\n",
    "plt.subplots(figsize=[20,300])\n",
    "k=1\n",
    "for col in num_col:\n",
    "    plt.subplot(int(len(num_col)/2)+1,4,k)\n",
    "    sns.barplot(data=train_df, x='churn_probability', y=col)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98eb614",
   "metadata": {},
   "source": [
    "As seen above there are many features which are having higher values for churn cases compared to non churn cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a681caec",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "sns.heatmap(tel_data[num_col].corr(), annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af558573",
   "metadata": {},
   "source": [
    "As seen in the heatmap there are multiple columns with high correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3378989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "arpu_8            total_rech_amt_8    0.955952\n",
      "arpu_6            total_rech_amt_6    0.953017\n",
      "arpu_7            total_rech_amt_7    0.951995\n",
      "isd_og_mou_7      isd_og_mou_8        0.931492\n",
      "isd_og_mou_6      isd_og_mou_7        0.912532\n",
      "                  isd_og_mou_8        0.906227\n",
      "loc_ic_mou_6      total_ic_mou_6      0.900520\n",
      "loc_ic_mou_8      total_ic_mou_8      0.889419\n",
      "loc_ic_mou_7      total_ic_mou_7      0.889352\n",
      "onnet_mou_8       std_og_t2t_mou_8    0.865969\n",
      "onnet_mou_7       std_og_t2t_mou_7    0.859510\n",
      "std_og_mou_8      total_og_mou_8      0.859191\n",
      "offnet_mou_8      std_og_t2m_mou_8    0.855728\n",
      "std_og_mou_7      total_og_mou_7      0.855199\n",
      "std_ic_t2m_mou_8  std_ic_mou_8        0.855070\n",
      "onnet_mou_6       std_og_t2t_mou_6    0.854038\n",
      "offnet_mou_7      std_og_t2m_mou_7    0.853607\n",
      "std_ic_t2m_mou_7  std_ic_mou_7        0.851653\n",
      "std_ic_t2m_mou_6  std_ic_mou_6        0.845302\n",
      "std_og_mou_6      total_og_mou_6      0.839788\n",
      "offnet_mou_6      std_og_t2m_mou_6    0.831991\n",
      "loc_og_mou_7      loc_og_mou_8        0.831337\n",
      "loc_ic_mou_7      loc_ic_mou_8        0.828171\n",
      "loc_ic_t2m_mou_8  loc_ic_mou_8        0.824756\n",
      "loc_ic_t2m_mou_6  loc_ic_mou_6        0.822578\n",
      "total_ic_mou_7    total_ic_mou_8      0.816474\n",
      "loc_og_t2m_mou_7  loc_og_t2m_mou_8    0.815376\n",
      "loc_og_t2m_mou_6  loc_og_mou_6        0.813077\n",
      "loc_og_t2t_mou_7  loc_og_t2t_mou_8    0.810679\n",
      "loc_og_mou_6      loc_og_mou_7        0.810401\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Lets check variables with high correlation\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "print(\"Top Absolute Correlations\")\n",
    "#displyaing top 30 best correlated pairs\n",
    "print(get_top_abs_correlations(tel_data[num_col], 30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807f122",
   "metadata": {},
   "source": [
    "As of now we are not going to drop any of the variables because by removing any variables we might lose some of the information. We will correlated variables during modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d844fa",
   "metadata": {},
   "source": [
    "#### 2.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabf927",
   "metadata": {},
   "source": [
    "We will drive new features based on given variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1544d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \n",
       "0           6/22/2014           7/10/2014           8/24/2014  \n",
       "1           6/12/2014           7/10/2014           8/26/2014  \n",
       "2           6/11/2014           7/22/2014           8/24/2014  \n",
       "3           6/15/2014           7/21/2014           8/25/2014  \n",
       "4           6/25/2014           7/26/2014           8/30/2014  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data[cat_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c241337",
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_data[cat_col] = tel_data[cat_col].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffe8bb",
   "metadata": {},
   "source": [
    "Our data is of period June 2014 to August 2014. We can create variables with no. of days since last recharge in each of the month from last day of month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e74a7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create seperate features for no. of days since last recharge \n",
    "tel_data['days_since_last_rech_6']= (tel_data['last_date_of_month_6']- tel_data['date_of_last_rech_6']).dt.days\n",
    "tel_data['days_since_last_rech_7']= (tel_data['last_date_of_month_7']- tel_data['date_of_last_rech_7']).dt.days\n",
    "tel_data['days_since_last_rech_8']= (tel_data['last_date_of_month_8']- tel_data['date_of_last_rech_8']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ebce93a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tel_data=tel_data.drop(cat_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097f533",
   "metadata": {},
   "source": [
    "# 4. Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f43390",
   "metadata": {},
   "source": [
    "#### 4.1  Filter high-value customers:\n",
    "As mentioned, we need to predict churn only for the high-value customers. Define high-value customers as follows: Those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "709ea3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#High Value Customer Extraction\n",
    "#lets extract high value customers based on the average recharge amount\n",
    "y_test_train=pd.concat([y_train,y_test], axis=0)\n",
    "tel_data['Churn']=y_test_train\n",
    "tel_data_hv=tel_data[tel_data[['total_rech_amt_6','total_rech_amt_7','total_rech_amt_8']].\\\n",
    "               mean(axis=1)> tel_data[['total_rech_amt_6','total_rech_amt_7','total_rech_amt_8']].mean(axis=1).quantile(0.7)]\n",
    "tel_data.drop(['Churn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e209050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29998, 128), (99999, 127))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_data_hv.shape,tel_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc225a9",
   "metadata": {},
   "source": [
    "#### 4.2 Train Test Split for Model 1 i.e. for purpose of Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e3cba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling class imbalance using smote for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43a86677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of label '1': 10191\n",
      "counts of label '0': 89808\n"
     ]
    }
   ],
   "source": [
    "#lets print the stats before sampling\n",
    "print(\"counts of label '1':\",sum(y_test_train==1))\n",
    "print(\"counts of label '0':\",sum(y_test_train==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dc12470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining X & Y\n",
    "X_hv=tel_data_hv.drop(['Churn'], axis=1)\n",
    "y_hv=tel_data_hv['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28c4fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_hv, X_test_hv, y_train_hv, y_test_hv=train_test_split(X_hv,y_hv, random_state=42, train_size=0.7, stratify=y_hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303e3ad",
   "metadata": {},
   "source": [
    "As seen above there is high class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c3544",
   "metadata": {},
   "source": [
    "#### Imbalanced Classes\n",
    "\n",
    "The problem we are trying to solve is a Classification Problem: we are trying to take each customer and classify them into either the Non-Churn Class (denoted as a 0) or the Churn Class (denoted as a 1).\n",
    "\n",
    "Whenever we have a classification problem, it is important to note how frequently we observe each class in the dataset. In our case, we have significantly more Non-Churn cases than we do Churn Cases, as we’d hope would be the case for any business.\n",
    "\n",
    "Noting class imbalances is important for evaluating modeling accuracy results.\n",
    "\n",
    "For example, if I told you the model I built classifies 84% of cases correctly, that might seem pretty good. But in this case, Non-Churn cases represent 84% of the data, so, in theory, the model could just classify everything as Non-Churn and achieve an 84% accuracy score.\n",
    "\n",
    "Therefore, when are evaluating model performance with an imbalanced dataset, we want to judge the model based mainly on how it performs on the minority class.\n",
    "\n",
    "##### Recall\n",
    "A Churn class Recall of 0.91 means that the model was able to catch 91% of the actual Churn cases. This is the measure we really care about, because we want to miss as few of the true Churn cases as possible.\n",
    "\n",
    "##### Precision\n",
    "Precision of the Churn class measures how often the model catches an actual Churn case, while also factoring in how often it misclassifies a Non-Churn case as a Churn case. In this case, a Churn Precision of 0.84 is not a problem because there are no significant consequences of identifying a customer as a Churn risk when they are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "291fbcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\rohit chaudhary\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rohit chaudhary\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\rohit chaudhary\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\rohit chaudhary\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\rohit chaudhary\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\rohit chaudhary\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "461920da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform oversampling using smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train_smo, y_train_smo = oversample.fit_resample(X_train_hv, y_train_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91b1d785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of label '1': 19702\n",
      "counts of label '0': 19702\n"
     ]
    }
   ],
   "source": [
    "#lets print the stats before sampling\n",
    "print(\"counts of label '1':\",sum(y_train_smo==1))\n",
    "print(\"counts of label '0':\",sum(y_train_smo==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20907d53",
   "metadata": {},
   "source": [
    "As seen above now there is no class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f7e2bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20998, 127), (20998,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hv.shape, y_train_hv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "695005fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39404, 127), (39404,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smo.shape, y_train_smo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6fc79",
   "metadata": {},
   "source": [
    "####  4.3 Defining X, y for Model 2 for submission in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29142b1",
   "metadata": {},
   "source": [
    "As data is already split in train and test in Kaggle, therefore train_test_splt id not performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1e9da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tel_data.iloc[0:69999 ,]\n",
    "X_test=tel_data.iloc[69999:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77f1b83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69999, 127), (30000, 127))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769d0c3",
   "metadata": {},
   "source": [
    "#### 4.4 Scaling of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd1a77",
   "metadata": {},
   "source": [
    "##### 4.4.1 For Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "451d7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler object\n",
    "scaler=MinMaxScaler()\n",
    "#Fit and transform in scaler objcet\n",
    "X_train_smo[X_train_smo.columns]=scaler.fit_transform(X_train_smo[X_train_smo.columns])\n",
    "#transforming test data\n",
    "X_test_hv[X_test_hv.columns]=scaler.transform(X_test_hv[X_test_hv.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5195b97",
   "metadata": {},
   "source": [
    "##### 4.4.2 For Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5088f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler object\n",
    "scaler=MinMaxScaler()\n",
    "#Fit and transform in scaler objcet\n",
    "X_train[X_train.columns]=scaler.fit_transform(X_train[X_train.columns])\n",
    "#transforming test data\n",
    "X_test[X_test.columns]=scaler.transform(X_test[X_test.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b51177",
   "metadata": {},
   "source": [
    "# 5. Model Development-Validation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5990e2",
   "metadata": {},
   "source": [
    "We will be creating two spearate models for follwing purposes:\n",
    "1. To predict whether a high-value customer will churn or not, in near future (i.e. churn phase). By knowing this, the company can take action steps such as providing special plans, discounts on recharge etc. and for this purpose best model is Logistic Regression ehich can be used to explain the result for all the customers.\n",
    "2. To predict highest acuuracy as overall accuracy is primary evaluation metric in Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a19f82",
   "metadata": {},
   "source": [
    "#### 5.1 Model 1 with Logistic Regression for High value customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04655887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Wall time: 5min 58s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=RFE(estimator=LogisticRegression()),\n",
       "             param_grid=[{&#x27;n_features_to_select&#x27;: [15, 25, 35, 45]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=RFE(estimator=LogisticRegression()),\n",
       "             param_grid=[{&#x27;n_features_to_select&#x27;: [15, 25, 35, 45]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RFE(estimator=LogisticRegression()),\n",
       "             param_grid=[{'n_features_to_select': [15, 25, 35, 45]}],\n",
       "             return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr=LogisticRegression()\n",
    "folds = 2\n",
    "lr.fit(X_train_smo, y_train_smo)\n",
    "rfe=RFE(lr)\n",
    "#As we don't want model to be complex checking behaviour of model upto 40 features\n",
    "hyper_params=[{'n_features_to_select':[15,25,35,45]}] \n",
    "cv_model=GridSearchCV(estimator=rfe,\n",
    "                      param_grid=hyper_params,\n",
    "                      scoring=\"accuracy\",\n",
    "                      cv=folds,\n",
    "                      verbose=1,\n",
    "                      return_train_score=True)\n",
    "cv_model.fit(X_train_smo, y_train_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1fce2b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_features_to_select': 45}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_resuls=pd.DataFrame(cv_model.cv_results_)\n",
    "cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ede5feeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets plot mean test and train score to calculate ideal no. of features\n",
    "cv_plot = cv_resuls\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(cv_plot[\"param_n_features_to_select\"],cv_plot[\"mean_test_score\"])\n",
    "plt.plot(cv_plot[\"param_n_features_to_select\"],cv_plot[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92a826f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=LogisticRegression(), n_features_to_select=35)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=LogisticRegression(), n_features_to_select=35)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=35)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets implement RFE to reduce features\n",
    "# define the method\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=35)\n",
    "# fit the model\n",
    "rfe.fit(X_train_smo, y_train_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ae522c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=X_train_smo.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81cf6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                Predicted\n",
    "#                           Not Churn     Churn\n",
    "#Actual Not churn              TN           FP \n",
    "#Actual Churn                  FN           TP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c032c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics(X,y,classifier, model):\n",
    "    metrics={}\n",
    "    y_pred=classifier.predict(X)\n",
    "    cm=confusion_matrix(y,y_pred)\n",
    "    TP=cm[1,1]\n",
    "    TN=cm[0,0]\n",
    "    FP=cm[0,1]\n",
    "    FN=cm[1,0]\n",
    "    Acc=100*round((TP+TN)/(TP+TN+FP+FN),4)\n",
    "    Sen=100*round((TP)/(TP+FN),4)\n",
    "    spec=100*round((TN)/(TN+FP),4)\n",
    "    prec=100*round((TP)/(TP+FP),4)\n",
    "    reca=100*round((TP)/(TP+FN),4)\n",
    "    TPR=100*round((TP)/(TP+FN),4)\n",
    "    FPR=100*round((FP)/(TN+FP),4)\n",
    "    return {'Model':model,'Accuracy':Acc,'Sensitivity':Sen,'Specificity':spec,'Precision':prec,'Recall':reca,\\\n",
    "            'True Positive rate':TPR,'False Positive rate':FPR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "829edecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train_smo[col], y_train_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f9ab66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression train</th>\n",
       "      <td>84.14</td>\n",
       "      <td>84.89</td>\n",
       "      <td>83.39</td>\n",
       "      <td>83.64</td>\n",
       "      <td>84.89</td>\n",
       "      <td>84.89</td>\n",
       "      <td>16.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression test</th>\n",
       "      <td>83.34</td>\n",
       "      <td>80.18</td>\n",
       "      <td>83.55</td>\n",
       "      <td>24.26</td>\n",
       "      <td>80.18</td>\n",
       "      <td>80.18</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Sensitivity  Specificity  Precision  \\\n",
       "Model                                                                      \n",
       "Logistic Regression train     84.14        84.89        83.39      83.64   \n",
       "Logistic Regression test      83.34        80.18        83.55      24.26   \n",
       "\n",
       "                           Recall  True Positive rate  False Positive rate  \n",
       "Model                                                                       \n",
       "Logistic Regression train   84.89               84.89                16.61  \n",
       "Logistic Regression test    80.18               80.18                16.45  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics=metrics.append(Metrics(X_train_smo[col], y_train_smo,logreg, 'Logistic Regression train'),ignore_index=True)\n",
    "metrics=metrics.append(Metrics(X_test_hv[col], y_test_hv,logreg, 'Logistic Regression test'),ignore_index=True)\n",
    "metrics.set_index(\"Model\", inplace=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9a10765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features = 50\n",
    "#Logistic Regression train\t84.30\t84.80\t83.81\t83.97\t84.80\t84.80\t16.19\n",
    "#Logistic Regression test\t83.76\t80.36\t83.98\t24.79\t80.36\t80.36\t16.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2691b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features = 45\n",
    "#Logistic Regression train\t84.19\t84.87\t83.51\t83.73\t84.87\t84.87\t16.49\n",
    "#Logistic Regression test\t83.87\t80.36\t84.10\t24.93\t80.36\t80.36\t15.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84b23401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features = 40\n",
    "#Logistic Regression train\t84.33\t85.18\t83.48\t83.76\t85.18\t85.18\t16.52\n",
    "#Logistic Regression test\t83.38\t80.36\t83.58\t24.33\t80.36\t80.36\t16.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba6bf12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features = 35\n",
    "#Logistic Regression train\t84.24\t85.24\t83.24\t83.56\t85.24\t85.24\t16.76\n",
    "#Logistic Regression test\t83.31\t80.18\t83.52\t24.22\t80.18\t80.18\t16.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af269a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features = 30\n",
    "#Logistic Regression train\t84.01\t84.85\t83.16\t83.44\t84.85\t84.85\t16.84\n",
    "#Logistic Regression test\t83.27\t80.18\t83.47\t24.17\t80.18\t80.18\t16.53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b5532",
   "metadata": {},
   "source": [
    "As seen above model performance for features =30,35,40,45,50, there is not much difference between the final performances, therefore n=35 has been considered as test score is not improving much after that as seen in plot above also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "148bc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check p value and VIF for model\n",
    "#Defining function for model and VIF\n",
    "def Stats_Model(X,y):\n",
    "    # add constant to X_train\n",
    "    global X_train_sm\n",
    "    X_train_sm= sm.add_constant(X)\n",
    "    global lr\n",
    "    lr=sm.GLM(y,X_train_sm, family=sm.families.Binomial())\n",
    "    Linear_model=lr.fit()\n",
    "    return Linear_model.summary()\n",
    "\n",
    "def VIF(X):\n",
    "    VIF=pd.DataFrame({\"Features\":X.columns})\n",
    "    VIF[\"vif\"]= [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    VIF[\"vif\"] =round(VIF[\"vif\"],2)\n",
    "    VIF=VIF.sort_values(by=\"vif\", ascending =False)\n",
    "    return VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0da1e93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39368\n",
      "Model Family:                Binomial   Df Model:                           35\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15158.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30317.\n",
      "Time:                        18:44:34   Pearson chi2:                 5.28e+08\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.6197      0.205     -3.028      0.002      -1.021      -0.219\n",
      "arpu_7                    13.8610      3.686      3.760      0.000       6.636      21.086\n",
      "roam_ic_mou_7              4.8055      0.852      5.637      0.000       3.135       6.476\n",
      "roam_og_mou_7              1.5565      0.585      2.660      0.008       0.410       2.703\n",
      "roam_og_mou_8             10.9740      0.938     11.693      0.000       9.135      12.813\n",
      "loc_og_t2m_mou_8          -9.4960      1.140     -8.330      0.000     -11.730      -7.262\n",
      "loc_og_t2f_mou_8          -4.3648      0.950     -4.597      0.000      -6.226      -2.504\n",
      "loc_og_mou_8              -4.2181      1.503     -2.807      0.005      -7.163      -1.273\n",
      "std_og_mou_7               6.7765      0.431     15.729      0.000       5.932       7.621\n",
      "spl_og_mou_8              -7.9814      1.493     -5.346      0.000     -10.907      -5.055\n",
      "total_og_mou_8           -12.5973      0.592    -21.293      0.000     -13.757     -11.438\n",
      "loc_ic_t2m_mou_7           2.1922      1.275      1.719      0.086      -0.308       4.692\n",
      "loc_ic_t2m_mou_8          -2.5553      2.718     -0.940      0.347      -7.883       2.772\n",
      "loc_ic_t2f_mou_6          -7.2627      1.913     -3.797      0.000     -11.011      -3.514\n",
      "loc_ic_t2f_mou_7         -10.9012      1.756     -6.209      0.000     -14.342      -7.460\n",
      "loc_ic_mou_7              20.3776      2.017     10.102      0.000      16.424      24.331\n",
      "loc_ic_mou_8              -2.2469      2.548     -0.882      0.378      -7.240       2.746\n",
      "std_ic_t2t_mou_6          11.4188      1.271      8.984      0.000       8.928      13.910\n",
      "total_ic_mou_8           -24.4516      1.496    -16.341      0.000     -27.384     -21.519\n",
      "spl_ic_mou_8              -9.0866      1.046     -8.691      0.000     -11.136      -7.037\n",
      "isd_ic_mou_8              14.7572      1.255     11.759      0.000      12.298      17.217\n",
      "total_rech_amt_6           8.6136      1.208      7.130      0.000       6.246      10.982\n",
      "total_rech_amt_7           1.5116      2.935      0.515      0.607      -4.242       7.265\n",
      "last_day_rch_amt_8       -12.9545      0.606    -21.389      0.000     -14.142     -11.767\n",
      "vol_2g_mb_6                6.7725      1.004      6.746      0.000       4.805       8.740\n",
      "vol_2g_mb_7                7.5310      0.726     10.371      0.000       6.108       8.954\n",
      "vol_3g_mb_6               12.9655      1.926      6.733      0.000       9.191      16.740\n",
      "vol_3g_mb_7               12.4678      1.137     10.969      0.000      10.240      14.696\n",
      "monthly_2g_6              -6.0067      0.393    -15.270      0.000      -6.778      -5.236\n",
      "monthly_2g_7              -7.1673      0.516    -13.889      0.000      -8.179      -6.156\n",
      "monthly_2g_8             -12.6645      0.735    -17.231      0.000     -14.105     -11.224\n",
      "sachet_2g_8              -18.4874      0.781    -23.684      0.000     -20.017     -16.958\n",
      "monthly_3g_6             -10.7361      0.947    -11.338      0.000     -12.592      -8.880\n",
      "monthly_3g_7              -6.5063      0.863     -7.543      0.000      -8.197      -4.816\n",
      "monthly_3g_8             -19.2919      1.105    -17.464      0.000     -21.457     -17.127\n",
      "days_since_last_rech_8     3.9701      0.099     40.027      0.000       3.776       4.165\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(Stats_Model(X_train_smo[col], y_train_smo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e14849ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39369\n",
      "Model Family:                Binomial   Df Model:                           34\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15159.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30317.\n",
      "Time:                        18:45:39   Pearson chi2:                 4.96e+08\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.7039      0.123     -5.724      0.000      -0.945      -0.463\n",
      "arpu_7                    15.4343      2.059      7.496      0.000      11.399      19.470\n",
      "roam_ic_mou_7              4.8057      0.852      5.638      0.000       3.135       6.476\n",
      "roam_og_mou_7              1.5637      0.585      2.674      0.008       0.417       2.710\n",
      "roam_og_mou_8             10.9872      0.938     11.709      0.000       9.148      12.826\n",
      "loc_og_t2m_mou_8          -9.4786      1.139     -8.320      0.000     -11.712      -7.246\n",
      "loc_og_t2f_mou_8          -4.3377      0.948     -4.578      0.000      -6.195      -2.481\n",
      "loc_og_mou_8              -4.2197      1.502     -2.808      0.005      -7.165      -1.275\n",
      "std_og_mou_7               6.7803      0.431     15.749      0.000       5.937       7.624\n",
      "spl_og_mou_8              -8.0094      1.493     -5.365      0.000     -10.936      -5.083\n",
      "total_og_mou_8           -12.5871      0.591    -21.293      0.000     -13.746     -11.429\n",
      "loc_ic_t2m_mou_7           2.1966      1.275      1.722      0.085      -0.303       4.696\n",
      "loc_ic_t2m_mou_8          -2.5782      2.718     -0.949      0.343      -7.905       2.748\n",
      "loc_ic_t2f_mou_6          -7.2859      1.912     -3.810      0.000     -11.034      -3.538\n",
      "loc_ic_t2f_mou_7         -10.8989      1.755     -6.209      0.000     -14.339      -7.459\n",
      "loc_ic_mou_7              20.3724      2.017     10.100      0.000      16.419      24.326\n",
      "loc_ic_mou_8              -2.2249      2.547     -0.873      0.382      -7.217       2.767\n",
      "std_ic_t2t_mou_6          11.4276      1.271      8.992      0.000       8.937      13.918\n",
      "total_ic_mou_8           -24.4663      1.496    -16.352      0.000     -27.399     -21.534\n",
      "spl_ic_mou_8              -9.0921      1.045     -8.698      0.000     -11.141      -7.043\n",
      "isd_ic_mou_8              14.7753      1.255     11.775      0.000      12.316      17.235\n",
      "total_rech_amt_6           8.5684      1.206      7.106      0.000       6.205      10.932\n",
      "last_day_rch_amt_8       -12.9670      0.606    -21.414      0.000     -14.154     -11.780\n",
      "vol_2g_mb_6                6.7666      1.004      6.740      0.000       4.799       8.734\n",
      "vol_2g_mb_7                7.5372      0.726     10.380      0.000       6.114       8.960\n",
      "vol_3g_mb_6               12.9537      1.926      6.725      0.000       9.178      16.729\n",
      "vol_3g_mb_7               12.4759      1.137     10.976      0.000      10.248      14.704\n",
      "monthly_2g_6              -6.0092      0.393    -15.274      0.000      -6.780      -5.238\n",
      "monthly_2g_7              -7.1665      0.516    -13.887      0.000      -8.178      -6.155\n",
      "monthly_2g_8             -12.6646      0.735    -17.232      0.000     -14.105     -11.224\n",
      "sachet_2g_8              -18.4905      0.781    -23.687      0.000     -20.020     -16.961\n",
      "monthly_3g_6             -10.7364      0.947    -11.336      0.000     -12.593      -8.880\n",
      "monthly_3g_7              -6.4979      0.862     -7.535      0.000      -8.188      -4.808\n",
      "monthly_3g_8             -19.2928      1.105    -17.464      0.000     -21.458     -17.128\n",
      "days_since_last_rech_8     3.9710      0.099     40.035      0.000       3.777       4.165\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Dropping total_rech_amt_7 due to high p value\n",
    "col=list(col)\n",
    "col.remove('total_rech_amt_7')\n",
    "print(Stats_Model(X_train_smo[col], y_train_smo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "941627d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39370\n",
      "Model Family:                Binomial   Df Model:                           33\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15159.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30318.\n",
      "Time:                        18:46:16   Pearson chi2:                 4.63e+08\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.7033      0.123     -5.720      0.000      -0.944      -0.462\n",
      "arpu_7                    15.4176      2.059      7.489      0.000      11.383      19.453\n",
      "roam_ic_mou_7              4.8228      0.852      5.660      0.000       3.153       6.493\n",
      "roam_og_mou_7              1.5514      0.585      2.654      0.008       0.406       2.697\n",
      "roam_og_mou_8             11.0388      0.938     11.774      0.000       9.201      12.876\n",
      "loc_og_t2m_mou_8          -9.4588      1.137     -8.320      0.000     -11.687      -7.230\n",
      "loc_og_t2f_mou_8          -4.3649      0.947     -4.610      0.000      -6.221      -2.509\n",
      "loc_og_mou_8              -4.2641      1.496     -2.851      0.004      -7.196      -1.332\n",
      "std_og_mou_7               6.7955      0.430     15.795      0.000       5.952       7.639\n",
      "spl_og_mou_8              -7.9979      1.492     -5.359      0.000     -10.923      -5.073\n",
      "total_og_mou_8           -12.5620      0.590    -21.278      0.000     -13.719     -11.405\n",
      "loc_ic_t2m_mou_7           2.6448      1.165      2.269      0.023       0.361       4.929\n",
      "loc_ic_t2m_mou_8          -4.1353      2.042     -2.025      0.043      -8.138      -0.133\n",
      "loc_ic_t2f_mou_6          -7.3618      1.911     -3.853      0.000     -11.107      -3.617\n",
      "loc_ic_t2f_mou_7         -10.8476      1.754     -6.186      0.000     -14.285      -7.411\n",
      "loc_ic_mou_7              19.5309      1.765     11.065      0.000      16.071      22.990\n",
      "std_ic_t2t_mou_6          11.6944      1.237      9.456      0.000       9.271      14.118\n",
      "total_ic_mou_8           -25.2578      1.202    -21.006      0.000     -27.614     -22.901\n",
      "spl_ic_mou_8              -9.0735      1.045     -8.683      0.000     -11.122      -7.025\n",
      "isd_ic_mou_8              15.2409      1.140     13.365      0.000      13.006      17.476\n",
      "total_rech_amt_6           8.5029      1.204      7.063      0.000       6.143      10.862\n",
      "last_day_rch_amt_8       -12.9627      0.606    -21.398      0.000     -14.150     -11.775\n",
      "vol_2g_mb_6                6.7576      1.004      6.731      0.000       4.790       8.725\n",
      "vol_2g_mb_7                7.5460      0.726     10.394      0.000       6.123       8.969\n",
      "vol_3g_mb_6               12.9381      1.926      6.718      0.000       9.163      16.713\n",
      "vol_3g_mb_7               12.4679      1.136     10.977      0.000      10.242      14.694\n",
      "monthly_2g_6              -6.0097      0.393    -15.273      0.000      -6.781      -5.238\n",
      "monthly_2g_7              -7.1664      0.516    -13.889      0.000      -8.178      -6.155\n",
      "monthly_2g_8             -12.6592      0.735    -17.222      0.000     -14.100     -11.219\n",
      "sachet_2g_8              -18.4884      0.781    -23.683      0.000     -20.018     -16.958\n",
      "monthly_3g_6             -10.7480      0.947    -11.347      0.000     -12.604      -8.891\n",
      "monthly_3g_7              -6.4884      0.862     -7.526      0.000      -8.178      -4.799\n",
      "monthly_3g_8             -19.2908      1.105    -17.465      0.000     -21.456     -17.126\n",
      "days_since_last_rech_8     3.9674      0.099     40.026      0.000       3.773       4.162\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Dropping loc_ic_mou_8 due to high p value\n",
    "col.remove('loc_ic_mou_8')\n",
    "print(Stats_Model(X_train_smo[col], y_train_smo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b80918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "      <td>9.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>loc_ic_t2m_mou_7</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arpu_7</td>\n",
       "      <td>7.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_ic_mou_8</td>\n",
       "      <td>7.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loc_og_mou_8</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_rech_amt_6</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vol_3g_mb_6</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vol_3g_mb_7</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>monthly_3g_7</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roam_og_mou_7</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>monthly_3g_6</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>loc_ic_t2f_mou_7</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loc_ic_t2f_mou_6</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>days_since_last_rech_8</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vol_2g_mb_6</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vol_2g_mb_7</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>monthly_2g_7</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>monthly_3g_8</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>monthly_2g_6</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roam_ic_mou_7</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>monthly_2g_8</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>isd_ic_mou_8</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sachet_2g_8</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spl_og_mou_8</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>std_ic_t2t_mou_6</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Features   vif\n",
       "14            loc_ic_mou_7  9.23\n",
       "10        loc_ic_t2m_mou_7  8.83\n",
       "0                   arpu_7  7.49\n",
       "16          total_ic_mou_8  7.29\n",
       "11        loc_ic_t2m_mou_8  6.95\n",
       "6             loc_og_mou_8  4.90\n",
       "4         loc_og_t2m_mou_8  4.42\n",
       "9           total_og_mou_8  3.94\n",
       "19        total_rech_amt_6  3.60\n",
       "23             vol_3g_mb_6  3.24\n",
       "7             std_og_mou_7  3.21\n",
       "24             vol_3g_mb_7  3.19\n",
       "30            monthly_3g_7  2.96\n",
       "2            roam_og_mou_7  2.90\n",
       "29            monthly_3g_6  2.83\n",
       "13        loc_ic_t2f_mou_7  2.51\n",
       "12        loc_ic_t2f_mou_6  2.39\n",
       "32  days_since_last_rech_8  2.12\n",
       "21             vol_2g_mb_6  2.11\n",
       "22             vol_2g_mb_7  2.09\n",
       "3            roam_og_mou_8  2.04\n",
       "26            monthly_2g_7  2.02\n",
       "31            monthly_3g_8  1.94\n",
       "25            monthly_2g_6  1.91\n",
       "1            roam_ic_mou_7  1.85\n",
       "27            monthly_2g_8  1.71\n",
       "20      last_day_rch_amt_8  1.58\n",
       "18            isd_ic_mou_8  1.29\n",
       "5         loc_og_t2f_mou_8  1.27\n",
       "28             sachet_2g_8  1.19\n",
       "8             spl_og_mou_8  1.16\n",
       "15        std_ic_t2t_mou_6  1.15\n",
       "17            spl_ic_mou_8  1.05"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now that all the varaibles are significant Checking VIF value\n",
    "VIF(X_train_smo[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91bb49d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39371\n",
      "Model Family:                Binomial   Df Model:                           32\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15214.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30427.\n",
      "Time:                        18:48:31   Pearson chi2:                 1.03e+09\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.7235      0.123     -5.868      0.000      -0.965      -0.482\n",
      "arpu_7                    15.9861      2.064      7.744      0.000      11.940      20.032\n",
      "roam_ic_mou_7              4.6684      0.843      5.537      0.000       3.016       6.321\n",
      "roam_og_mou_7              1.3660      0.582      2.348      0.019       0.226       2.506\n",
      "roam_og_mou_8             11.0731      0.935     11.841      0.000       9.240      12.906\n",
      "loc_og_t2m_mou_8         -12.0166      1.069    -11.237      0.000     -14.113      -9.921\n",
      "loc_og_t2f_mou_8          -5.1336      0.951     -5.396      0.000      -6.998      -3.269\n",
      "loc_og_mou_8               0.7694      1.342      0.574      0.566      -1.860       3.399\n",
      "std_og_mou_7               6.8821      0.430     15.998      0.000       6.039       7.725\n",
      "spl_og_mou_8              -8.0697      1.495     -5.398      0.000     -10.999      -5.140\n",
      "total_og_mou_8           -13.1309      0.590    -22.248      0.000     -14.288     -11.974\n",
      "loc_ic_t2m_mou_7          12.4154      0.762     16.300      0.000      10.923      13.908\n",
      "loc_ic_t2m_mou_8          -8.9807      1.987     -4.521      0.000     -12.874      -5.087\n",
      "loc_ic_t2f_mou_6          -7.2243      1.875     -3.854      0.000     -10.898      -3.550\n",
      "loc_ic_t2f_mou_7          -6.9382      1.689     -4.107      0.000     -10.250      -3.627\n",
      "std_ic_t2t_mou_6          10.3343      1.214      8.514      0.000       7.955      12.713\n",
      "total_ic_mou_8           -20.5701      1.122    -18.330      0.000     -22.770     -18.371\n",
      "spl_ic_mou_8              -9.2912      1.048     -8.868      0.000     -11.345      -7.238\n",
      "isd_ic_mou_8              12.6115      1.120     11.259      0.000      10.416      14.807\n",
      "total_rech_amt_6           8.9271      1.203      7.423      0.000       6.570      11.284\n",
      "last_day_rch_amt_8       -12.9869      0.606    -21.443      0.000     -14.174     -11.800\n",
      "vol_2g_mb_6                6.6775      1.004      6.648      0.000       4.709       8.646\n",
      "vol_2g_mb_7                7.5590      0.728     10.386      0.000       6.133       8.985\n",
      "vol_3g_mb_6               13.0258      1.926      6.764      0.000       9.252      16.800\n",
      "vol_3g_mb_7               12.3139      1.128     10.920      0.000      10.104      14.524\n",
      "monthly_2g_6              -5.9516      0.393    -15.155      0.000      -6.721      -5.182\n",
      "monthly_2g_7              -7.2065      0.515    -13.987      0.000      -8.216      -6.197\n",
      "monthly_2g_8             -12.6795      0.735    -17.257      0.000     -14.120     -11.239\n",
      "sachet_2g_8              -18.4811      0.780    -23.706      0.000     -20.009     -16.953\n",
      "monthly_3g_6             -10.5398      0.942    -11.193      0.000     -12.385      -8.694\n",
      "monthly_3g_7              -6.4450      0.860     -7.496      0.000      -8.130      -4.760\n",
      "monthly_3g_8             -19.6106      1.106    -17.732      0.000     -21.778     -17.443\n",
      "days_since_last_rech_8     3.9947      0.099     40.431      0.000       3.801       4.188\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# dropping loc_ic_mou_7 due to high VIF\n",
    "col.remove('loc_ic_mou_7')\n",
    "print(Stats_Model(X_train_smo[col], y_train_smo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d1b0b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39372\n",
      "Model Family:                Binomial   Df Model:                           31\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15214.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30427.\n",
      "Time:                        18:49:01   Pearson chi2:                 1.20e+09\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.7292      0.123     -5.918      0.000      -0.971      -0.488\n",
      "arpu_7                    16.0937      2.061      7.810      0.000      12.055      20.133\n",
      "roam_ic_mou_7              4.6574      0.843      5.526      0.000       3.006       6.309\n",
      "roam_og_mou_7              1.3556      0.582      2.331      0.020       0.216       2.495\n",
      "roam_og_mou_8             11.0780      0.935     11.846      0.000       9.245      12.911\n",
      "loc_og_t2m_mou_8         -11.6198      0.817    -14.227      0.000     -13.221     -10.019\n",
      "loc_og_t2f_mou_8          -5.1082      0.951     -5.373      0.000      -6.972      -3.245\n",
      "std_og_mou_7               6.8124      0.412     16.517      0.000       6.004       7.621\n",
      "spl_og_mou_8              -8.0999      1.494     -5.420      0.000     -11.029      -5.171\n",
      "total_og_mou_8           -13.0325      0.564    -23.113      0.000     -14.138     -11.927\n",
      "loc_ic_t2m_mou_7          12.4154      0.762     16.293      0.000      10.922      13.909\n",
      "loc_ic_t2m_mou_8          -9.0968      1.976     -4.604      0.000     -12.970      -5.224\n",
      "loc_ic_t2f_mou_6          -7.2038      1.874     -3.843      0.000     -10.878      -3.530\n",
      "loc_ic_t2f_mou_7          -6.9471      1.689     -4.112      0.000     -10.258      -3.636\n",
      "std_ic_t2t_mou_6          10.2787      1.209      8.500      0.000       7.909      12.649\n",
      "total_ic_mou_8           -20.4614      1.106    -18.506      0.000     -22.628     -18.294\n",
      "spl_ic_mou_8              -9.3111      1.047     -8.891      0.000     -11.364      -7.259\n",
      "isd_ic_mou_8              12.5389      1.113     11.269      0.000      10.358      14.720\n",
      "total_rech_amt_6           8.9560      1.202      7.450      0.000       6.600      11.312\n",
      "last_day_rch_amt_8       -13.0060      0.605    -21.503      0.000     -14.191     -11.820\n",
      "vol_2g_mb_6                6.6735      1.004      6.644      0.000       4.705       8.642\n",
      "vol_2g_mb_7                7.5538      0.728     10.379      0.000       6.127       8.980\n",
      "vol_3g_mb_6               13.0108      1.925      6.757      0.000       9.237      16.785\n",
      "vol_3g_mb_7               12.3258      1.128     10.924      0.000      10.114      14.537\n",
      "monthly_2g_6              -5.9499      0.393    -15.152      0.000      -6.720      -5.180\n",
      "monthly_2g_7              -7.2117      0.515    -13.999      0.000      -8.221      -6.202\n",
      "monthly_2g_8             -12.6784      0.735    -17.255      0.000     -14.119     -11.238\n",
      "sachet_2g_8              -18.4759      0.779    -23.705      0.000     -20.004     -16.948\n",
      "monthly_3g_6             -10.5448      0.942    -11.198      0.000     -12.390      -8.699\n",
      "monthly_3g_7              -6.4559      0.860     -7.509      0.000      -8.141      -4.771\n",
      "monthly_3g_8             -19.6086      1.106    -17.727      0.000     -21.777     -17.441\n",
      "days_since_last_rech_8     3.9982      0.099     40.532      0.000       3.805       4.191\n",
      "==========================================================================================\n",
      "                  Features   vif\n",
      "0                   arpu_7  7.46\n",
      "10        loc_ic_t2m_mou_8  6.08\n",
      "14          total_ic_mou_8  5.24\n",
      "17        total_rech_amt_6  3.58\n",
      "9         loc_ic_t2m_mou_7  3.37\n",
      "8           total_og_mou_8  3.35\n",
      "21             vol_3g_mb_6  3.24\n",
      "22             vol_3g_mb_7  3.19\n",
      "28            monthly_3g_7  2.96\n",
      "6             std_og_mou_7  2.95\n",
      "2            roam_og_mou_7  2.89\n",
      "27            monthly_3g_6  2.83\n",
      "4         loc_og_t2m_mou_8  2.49\n",
      "12        loc_ic_t2f_mou_7  2.43\n",
      "11        loc_ic_t2f_mou_6  2.39\n",
      "19             vol_2g_mb_6  2.11\n",
      "30  days_since_last_rech_8  2.10\n",
      "20             vol_2g_mb_7  2.09\n",
      "3            roam_og_mou_8  2.03\n",
      "24            monthly_2g_7  2.02\n",
      "29            monthly_3g_8  1.94\n",
      "23            monthly_2g_6  1.91\n",
      "1            roam_ic_mou_7  1.85\n",
      "25            monthly_2g_8  1.71\n",
      "18      last_day_rch_amt_8  1.57\n",
      "5         loc_og_t2f_mou_8  1.26\n",
      "16            isd_ic_mou_8  1.23\n",
      "26             sachet_2g_8  1.19\n",
      "7             spl_og_mou_8  1.16\n",
      "13        std_ic_t2t_mou_6  1.13\n",
      "15            spl_ic_mou_8  1.05\n"
     ]
    }
   ],
   "source": [
    "# dropping loc_og_mou_8 due to high p value\n",
    "col.remove('loc_og_mou_8')\n",
    "print(Stats_Model(X_train_smo[col], y_train_smo))\n",
    "print(VIF(X_train_smo[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2c7eef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39373\n",
      "Model Family:                Binomial   Df Model:                           30\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15250.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30500.\n",
      "Time:                        18:49:32   Pearson chi2:                 1.35e+07\n",
      "No. Iterations:                     7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      0.1944      0.035      5.499      0.000       0.125       0.264\n",
      "roam_ic_mou_7              4.7159      0.846      5.573      0.000       3.057       6.375\n",
      "roam_og_mou_7              2.1472      0.576      3.728      0.000       1.018       3.276\n",
      "roam_og_mou_8             11.0919      0.935     11.867      0.000       9.260      12.924\n",
      "loc_og_t2m_mou_8         -10.7612      0.800    -13.447      0.000     -12.330      -9.193\n",
      "loc_og_t2f_mou_8          -4.3931      0.927     -4.737      0.000      -6.211      -2.575\n",
      "std_og_mou_7               8.0328      0.381     21.095      0.000       7.286       8.779\n",
      "spl_og_mou_8              -7.6491      1.474     -5.189      0.000     -10.538      -4.760\n",
      "total_og_mou_8           -13.0803      0.565    -23.147      0.000     -14.188     -11.973\n",
      "loc_ic_t2m_mou_7          13.3281      0.754     17.681      0.000      11.851      14.806\n",
      "loc_ic_t2m_mou_8         -11.2223      1.951     -5.753      0.000     -15.045      -7.399\n",
      "loc_ic_t2f_mou_6          -8.1650      1.871     -4.364      0.000     -11.832      -4.498\n",
      "loc_ic_t2f_mou_7          -6.0699      1.674     -3.626      0.000      -9.351      -2.789\n",
      "std_ic_t2t_mou_6           9.6495      1.195      8.077      0.000       7.308      11.991\n",
      "total_ic_mou_8           -19.5352      1.084    -18.015      0.000     -21.661     -17.410\n",
      "spl_ic_mou_8              -9.4509      1.050     -9.001      0.000     -11.509      -7.393\n",
      "isd_ic_mou_8              12.6951      1.107     11.467      0.000      10.525      14.865\n",
      "total_rech_amt_6          13.1849      1.106     11.916      0.000      11.016      15.354\n",
      "last_day_rch_amt_8       -12.5413      0.599    -20.943      0.000     -13.715     -11.368\n",
      "vol_2g_mb_6                6.4404      1.004      6.417      0.000       4.473       8.408\n",
      "vol_2g_mb_7                8.1205      0.723     11.235      0.000       6.704       9.537\n",
      "vol_3g_mb_6               12.3705      1.854      6.673      0.000       8.737      16.004\n",
      "vol_3g_mb_7               13.7764      1.107     12.444      0.000      11.607      15.946\n",
      "monthly_2g_6              -6.0965      0.391    -15.607      0.000      -6.862      -5.331\n",
      "monthly_2g_7              -7.0285      0.510    -13.783      0.000      -8.028      -6.029\n",
      "monthly_2g_8             -12.7580      0.734    -17.372      0.000     -14.197     -11.319\n",
      "sachet_2g_8              -18.5189      0.779    -23.768      0.000     -20.046     -16.992\n",
      "monthly_3g_6             -10.8234      0.924    -11.710      0.000     -12.635      -9.012\n",
      "monthly_3g_7              -5.5702      0.847     -6.573      0.000      -7.231      -3.909\n",
      "monthly_3g_8             -19.9482      1.101    -18.123      0.000     -22.106     -17.791\n",
      "days_since_last_rech_8     3.9726      0.098     40.335      0.000       3.780       4.166\n",
      "==========================================================================================\n",
      "                  Features   vif\n",
      "9         loc_ic_t2m_mou_8  6.08\n",
      "13          total_ic_mou_8  5.17\n",
      "8         loc_ic_t2m_mou_7  3.31\n",
      "7           total_og_mou_8  3.28\n",
      "20             vol_3g_mb_6  3.23\n",
      "21             vol_3g_mb_7  3.17\n",
      "27            monthly_3g_7  2.95\n",
      "1            roam_og_mou_7  2.88\n",
      "26            monthly_3g_6  2.83\n",
      "16        total_rech_amt_6  2.81\n",
      "5             std_og_mou_7  2.61\n",
      "3         loc_og_t2m_mou_8  2.46\n",
      "11        loc_ic_t2f_mou_7  2.43\n",
      "10        loc_ic_t2f_mou_6  2.38\n",
      "18             vol_2g_mb_6  2.11\n",
      "19             vol_2g_mb_7  2.08\n",
      "2            roam_og_mou_8  2.03\n",
      "23            monthly_2g_7  2.02\n",
      "28            monthly_3g_8  1.94\n",
      "22            monthly_2g_6  1.91\n",
      "0            roam_ic_mou_7  1.83\n",
      "29  days_since_last_rech_8  1.75\n",
      "24            monthly_2g_8  1.70\n",
      "17      last_day_rch_amt_8  1.55\n",
      "4         loc_og_t2f_mou_8  1.26\n",
      "15            isd_ic_mou_8  1.22\n",
      "25             sachet_2g_8  1.16\n",
      "6             spl_og_mou_8  1.15\n",
      "12        std_ic_t2t_mou_6  1.13\n",
      "14            spl_ic_mou_8  1.04\n"
     ]
    }
   ],
   "source": [
    "# dropping arpu_7 due to high VIF\n",
    "col.remove('arpu_7')\n",
    "print(Stats_Model(X_train_smo[col], y_train_smo))\n",
    "print(VIF(X_train_smo[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b2f41b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Churn   No. Observations:                39404\n",
      "Model:                            GLM   Df Residuals:                    39374\n",
      "Model Family:                Binomial   Df Model:                           29\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15267.\n",
      "Date:                Mon, 11 Jul 2022   Deviance:                       30534.\n",
      "Time:                        18:50:01   Pearson chi2:                 9.65e+06\n",
      "No. Iterations:                     7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      0.1928      0.035      5.454      0.000       0.124       0.262\n",
      "roam_ic_mou_7              4.7357      0.858      5.517      0.000       3.053       6.418\n",
      "roam_og_mou_7              2.0645      0.585      3.532      0.000       0.919       3.210\n",
      "roam_og_mou_8             11.5593      0.942     12.270      0.000       9.713      13.406\n",
      "loc_og_t2m_mou_8         -11.7902      0.780    -15.108      0.000     -13.320     -10.261\n",
      "loc_og_t2f_mou_8          -4.2212      0.923     -4.574      0.000      -6.030      -2.412\n",
      "std_og_mou_7               8.0920      0.381     21.244      0.000       7.345       8.839\n",
      "spl_og_mou_8              -7.5977      1.472     -5.163      0.000     -10.482      -4.713\n",
      "total_og_mou_8           -12.9316      0.564    -22.932      0.000     -14.037     -11.826\n",
      "loc_ic_t2m_mou_7          10.8580      0.595     18.256      0.000       9.692      12.024\n",
      "loc_ic_t2f_mou_6          -7.9819      1.859     -4.293      0.000     -11.626      -4.338\n",
      "loc_ic_t2f_mou_7          -5.5658      1.649     -3.374      0.001      -8.799      -2.333\n",
      "std_ic_t2t_mou_6          11.2182      1.189      9.432      0.000       8.887      13.549\n",
      "total_ic_mou_8           -23.8056      0.840    -28.356      0.000     -25.451     -22.160\n",
      "spl_ic_mou_8              -9.3901      1.048     -8.956      0.000     -11.445      -7.335\n",
      "isd_ic_mou_8              15.1203      1.036     14.599      0.000      13.090      17.150\n",
      "total_rech_amt_6          13.2169      1.108     11.927      0.000      11.045      15.389\n",
      "last_day_rch_amt_8       -12.6472      0.600    -21.062      0.000     -13.824     -11.470\n",
      "vol_2g_mb_6                6.3614      1.003      6.345      0.000       4.397       8.326\n",
      "vol_2g_mb_7                8.0531      0.720     11.184      0.000       6.642       9.464\n",
      "vol_3g_mb_6               12.1506      1.853      6.556      0.000       8.518      15.783\n",
      "vol_3g_mb_7               13.7118      1.108     12.380      0.000      11.541      15.883\n",
      "monthly_2g_6              -6.1097      0.391    -15.609      0.000      -6.877      -5.343\n",
      "monthly_2g_7              -6.9357      0.510    -13.602      0.000      -7.935      -5.936\n",
      "monthly_2g_8             -12.7547      0.734    -17.379      0.000     -14.193     -11.316\n",
      "sachet_2g_8              -18.4462      0.777    -23.739      0.000     -19.969     -16.923\n",
      "monthly_3g_6             -10.8484      0.926    -11.717      0.000     -12.663      -9.034\n",
      "monthly_3g_7              -5.4572      0.847     -6.444      0.000      -7.117      -3.797\n",
      "monthly_3g_8             -19.9930      1.102    -18.143      0.000     -22.153     -17.833\n",
      "days_since_last_rech_8     3.9860      0.099     40.390      0.000       3.793       4.179\n",
      "==========================================================================================\n",
      "                  Features   vif\n",
      "7           total_og_mou_8  3.26\n",
      "19             vol_3g_mb_6  3.23\n",
      "20             vol_3g_mb_7  3.16\n",
      "12          total_ic_mou_8  3.12\n",
      "26            monthly_3g_7  2.95\n",
      "1            roam_og_mou_7  2.88\n",
      "25            monthly_3g_6  2.83\n",
      "15        total_rech_amt_6  2.81\n",
      "5             std_og_mou_7  2.61\n",
      "8         loc_ic_t2m_mou_7  2.46\n",
      "10        loc_ic_t2f_mou_7  2.42\n",
      "9         loc_ic_t2f_mou_6  2.38\n",
      "3         loc_og_t2m_mou_8  2.32\n",
      "17             vol_2g_mb_6  2.11\n",
      "18             vol_2g_mb_7  2.08\n",
      "22            monthly_2g_7  2.02\n",
      "2            roam_og_mou_8  2.02\n",
      "27            monthly_3g_8  1.94\n",
      "21            monthly_2g_6  1.90\n",
      "0            roam_ic_mou_7  1.83\n",
      "28  days_since_last_rech_8  1.74\n",
      "23            monthly_2g_8  1.70\n",
      "16      last_day_rch_amt_8  1.55\n",
      "4         loc_og_t2f_mou_8  1.26\n",
      "14            isd_ic_mou_8  1.17\n",
      "24             sachet_2g_8  1.16\n",
      "6             spl_og_mou_8  1.15\n",
      "11        std_ic_t2t_mou_6  1.10\n",
      "13            spl_ic_mou_8  1.04\n"
     ]
    }
   ],
   "source": [
    "# dropping loc_ic_t2m_mou_8   due to high VIF\n",
    "col.remove('loc_ic_t2m_mou_8')\n",
    "print(Stats_Model(X_train_smo[col], y_train_smo))\n",
    "print(VIF(X_train_smo[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68411b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avove model is acceptable as model is having p values less than 5% and  VIF less than 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e2ad2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistics regression on these features\n",
    "logreg.fit(X_train_smo[col], y_train_smo)\n",
    "y_train_pred_hv=logreg.predict(X_train_smo[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7868690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression train</th>\n",
       "      <td>83.99</td>\n",
       "      <td>84.53</td>\n",
       "      <td>83.45</td>\n",
       "      <td>83.63</td>\n",
       "      <td>84.53</td>\n",
       "      <td>84.53</td>\n",
       "      <td>16.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression test</th>\n",
       "      <td>83.31</td>\n",
       "      <td>79.10</td>\n",
       "      <td>83.59</td>\n",
       "      <td>24.05</td>\n",
       "      <td>79.10</td>\n",
       "      <td>79.10</td>\n",
       "      <td>16.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Sensitivity  Specificity  Precision  \\\n",
       "Model                                                                      \n",
       "Logistic Regression train     83.99        84.53        83.45      83.63   \n",
       "Logistic Regression test      83.31        79.10        83.59      24.05   \n",
       "\n",
       "                           Recall  True Positive rate  False Positive rate  \n",
       "Model                                                                       \n",
       "Logistic Regression train   84.53               84.53                16.55  \n",
       "Logistic Regression test    79.10               79.10                16.41  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics=metrics.append(Metrics(X_train_smo[col], y_train_smo,logreg, 'Logistic Regression train'),ignore_index=True)\n",
    "metrics=metrics.append(Metrics(X_test_hv[col], y_test_hv,logreg, 'Logistic Regression test'),ignore_index=True)\n",
    "metrics.set_index(\"Model\", inplace=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd8d84",
   "metadata": {},
   "source": [
    "There is not much drop in accuracy of model for train and test model even after dropping  multiple features due to high VIF and p value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc53d61",
   "metadata": {},
   "source": [
    "As in instant case we are interested in Sensitivity recall score, lets create model with optimum probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "91ae1737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted_churn_probability\n",
    "y_train_pred_proba=logreg.predict_proba(X_train_smo[col])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52688545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Churn</th>\n",
       "      <th>Predicted_churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.917652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.274734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual_Churn  Predicted_churn_probability\n",
       "0             0                     0.917652\n",
       "1             0                     0.274734\n",
       "2             0                     0.045256\n",
       "3             0                     0.005543\n",
       "4             0                     0.045464"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction =pd.DataFrame({\"Actual_Churn\":y_train_smo, \"Predicted_churn_probability\":y_train_pred_proba})\n",
    "Prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91e3e5",
   "metadata": {},
   "source": [
    "#### Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69913882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimal cutoof point is tradeoff between sensitivity and specificity.\n",
    "probabilities =[float(i/10) for i in range(10)]\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5a8741a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Churn</th>\n",
       "      <th>Predicted_churn_probability</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.917652</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.274734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual_Churn  Predicted_churn_probability  0.0  0.1  0.2  0.3  0.4  0.5  \\\n",
       "0             0                     0.917652    1    1    1    1    1    1   \n",
       "1             0                     0.274734    1    1    1    0    0    0   \n",
       "2             0                     0.045256    1    0    0    0    0    0   \n",
       "3             0                     0.005543    1    0    0    0    0    0   \n",
       "4             0                     0.045464    1    0    0    0    0    0   \n",
       "\n",
       "   0.6  0.7  0.8  0.9  \n",
       "0    1    1    1    1  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in probabilities:\n",
    "    Prediction[i]= Prediction[\"Predicted_churn_probability\"].map(lambda x : 1 if x>i else 0)\n",
    "Prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a752229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.987666</td>\n",
       "      <td>0.330728</td>\n",
       "      <td>0.659197</td>\n",
       "      <td>0.987666</td>\n",
       "      <td>0.596079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.967719</td>\n",
       "      <td>0.485484</td>\n",
       "      <td>0.726601</td>\n",
       "      <td>0.967719</td>\n",
       "      <td>0.652878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.778652</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>0.710797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>0.733225</td>\n",
       "      <td>0.814790</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>0.770641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.834484</td>\n",
       "      <td>0.839889</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.836254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.769770</td>\n",
       "      <td>0.898183</td>\n",
       "      <td>0.833976</td>\n",
       "      <td>0.769770</td>\n",
       "      <td>0.883182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.659730</td>\n",
       "      <td>0.937367</td>\n",
       "      <td>0.798548</td>\n",
       "      <td>0.659730</td>\n",
       "      <td>0.913294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.965029</td>\n",
       "      <td>0.726424</td>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.933107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.272307</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>0.628464</td>\n",
       "      <td>0.272307</td>\n",
       "      <td>0.946542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prob  Sensitivity  Specificity  Accuracy    recall  Precision\n",
       "0.0   0.0     1.000000     0.000000  0.500000  1.000000   0.500000\n",
       "0.1   0.1     0.987666     0.330728  0.659197  0.987666   0.596079\n",
       "0.2   0.2     0.967719     0.485484  0.726601  0.967719   0.652878\n",
       "0.3   0.3     0.939600     0.617704  0.778652  0.939600   0.710797\n",
       "0.4   0.4     0.896356     0.733225  0.814790  0.896356   0.770641\n",
       "0.5   0.5     0.845295     0.834484  0.839889  0.845295   0.836254\n",
       "0.6   0.6     0.769770     0.898183  0.833976  0.769770   0.883182\n",
       "0.7   0.7     0.659730     0.937367  0.798548  0.659730   0.913294\n",
       "0.8   0.8     0.487818     0.965029  0.726424  0.487818   0.933107\n",
       "0.9   0.9     0.272307     0.984621  0.628464  0.272307   0.946542"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metrics_df= pd.DataFrame(columns=['prob','Sensitivity','Specificity','Accuracy','recall', 'Precision'])\n",
    "prob=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in prob:\n",
    "    cm = confusion_matrix(Prediction.Actual_Churn,Prediction[i])\n",
    "    TP=cm[1,1]\n",
    "    FP=cm[0,1]\n",
    "    FN=cm[1,0]\n",
    "    TN=cm[0,0]\n",
    "    Sensitivity= (TP/(TP+FN))\n",
    "    Specificity= (TN/(TN+FP))\n",
    "    Accuracy= ((TN+TP)/(TN+FP+FN+TP))\n",
    "    recall=Sensitivity\n",
    "    Precision=(TP/(TP+FP))\n",
    "    \n",
    "    Metrics_df.loc[i] =[ i ,Sensitivity,Specificity,Accuracy, recall, Precision]\n",
    "Metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8edf5c",
   "metadata": {},
   "source": [
    "##### Recall Precision tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a835e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Metrics_df.prob,Metrics_df.recall, color='r')\n",
    "plt.plot(Metrics_df.prob,Metrics_df.Precision, color='g')\n",
    "plt.plot(Metrics_df.prob,Metrics_df.Accuracy, color='b')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a09430",
   "metadata": {},
   "source": [
    "###### Sensitivity Specificity tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a4051ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Metrics_df.prob,Metrics_df.Specificity, color='r')\n",
    "plt.plot(Metrics_df.prob,Metrics_df.Sensitivity, color='g')\n",
    "plt.plot(Metrics_df.prob,Metrics_df.Accuracy, color='b')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc37dd",
   "metadata": {},
   "source": [
    "As seen above Recall-Precisison , Specificity and sensitivity trade off curves are both indicating optimum probability as 0.5, therefore no change is required in optimum probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "83d45c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_proba=logreg.predict_proba(X_test_hv[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "936cb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr,fpr,thres= roc_curve(y_test_hv,y_test_pred_proba[:,1],drop_intermediate =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8ef326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tpr,fpr)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b2102fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8134"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_under_curve= roc_auc_score(y_test_hv,logreg.predict(X_test_hv[col]))\n",
    "round(area_under_curve,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "38ff8f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_ic_mou_8</td>\n",
       "      <td>-15.630478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>-12.900722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sachet_2g_8</td>\n",
       "      <td>-11.257954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>monthly_3g_8</td>\n",
       "      <td>-10.477346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>-10.278543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>-10.189718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>monthly_2g_8</td>\n",
       "      <td>-8.979103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>8.038901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_rech_amt_6</td>\n",
       "      <td>7.672018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>7.013549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vol_3g_mb_7</td>\n",
       "      <td>6.722344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>monthly_3g_6</td>\n",
       "      <td>-5.941595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "      <td>-5.476854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>monthly_2g_7</td>\n",
       "      <td>-5.295222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>isd_ic_mou_8</td>\n",
       "      <td>5.104869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loc_ic_t2m_mou_7</td>\n",
       "      <td>4.886942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vol_2g_mb_7</td>\n",
       "      <td>4.867925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>monthly_2g_6</td>\n",
       "      <td>-4.735239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>-4.556718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_ic_t2t_mou_6</td>\n",
       "      <td>4.353411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>monthly_3g_7</td>\n",
       "      <td>-4.304064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>days_since_last_rech_8</td>\n",
       "      <td>3.953113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loc_ic_t2f_mou_6</td>\n",
       "      <td>-3.763205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>loc_ic_t2f_mou_7</td>\n",
       "      <td>-3.657049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roam_og_mou_7</td>\n",
       "      <td>3.526101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vol_3g_mb_6</td>\n",
       "      <td>3.498934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roam_ic_mou_7</td>\n",
       "      <td>3.374709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vol_2g_mb_6</td>\n",
       "      <td>3.306450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spl_og_mou_8</td>\n",
       "      <td>-3.261997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Features      Coeff\n",
       "12          total_ic_mou_8 -15.630478\n",
       "7           total_og_mou_8 -12.900722\n",
       "24             sachet_2g_8 -11.257954\n",
       "27            monthly_3g_8 -10.477346\n",
       "16      last_day_rch_amt_8 -10.278543\n",
       "3         loc_og_t2m_mou_8 -10.189718\n",
       "23            monthly_2g_8  -8.979103\n",
       "5             std_og_mou_7   8.038901\n",
       "15        total_rech_amt_6   7.672018\n",
       "2            roam_og_mou_8   7.013549\n",
       "20             vol_3g_mb_7   6.722344\n",
       "25            monthly_3g_6  -5.941595\n",
       "13            spl_ic_mou_8  -5.476854\n",
       "22            monthly_2g_7  -5.295222\n",
       "14            isd_ic_mou_8   5.104869\n",
       "8         loc_ic_t2m_mou_7   4.886942\n",
       "18             vol_2g_mb_7   4.867925\n",
       "21            monthly_2g_6  -4.735239\n",
       "4         loc_og_t2f_mou_8  -4.556718\n",
       "11        std_ic_t2t_mou_6   4.353411\n",
       "26            monthly_3g_7  -4.304064\n",
       "28  days_since_last_rech_8   3.953113\n",
       "9         loc_ic_t2f_mou_6  -3.763205\n",
       "10        loc_ic_t2f_mou_7  -3.657049\n",
       "1            roam_og_mou_7   3.526101\n",
       "19             vol_3g_mb_6   3.498934\n",
       "0            roam_ic_mou_7   3.374709\n",
       "17             vol_2g_mb_6   3.306450\n",
       "6             spl_og_mou_8  -3.261997"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_feature=pd.DataFrame({'Features': X_test_hv[col].columns,'Coeff':logreg.coef_.reshape(-1)})\n",
    "imp_feature=imp_feature.sort_values(by='Coeff',key=abs,  ascending =False)\n",
    "imp_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1968de",
   "metadata": {},
   "source": [
    "Thus important factors for predicting whether a customer is going to churn are:\n",
    "- total_ic_mou_8: Total incoming minutes of usage in voice calls in August.\n",
    "- total_og_mou_8: Total outgoing minutes of usage in voice calls in August.\n",
    "- sachet_2g_8: Service schemes with validity smaller than a month for 2g in August.\n",
    "- monthly_3g_8: Service schemes with validity equivalent to a month for 3G in August\n",
    "- last_day_rch_amt_8:Last Day recharge amount for August.\n",
    "- loc_og_t2m_mou_8: Minutes of usage in Outgoing Local voice calls within same telecom circle with different mobile operator in August.\n",
    "- monthly_2g_8:Service schemes with validity equivalent to a month for 2G in August\n",
    "- std_og_mou_7: Minutes of usage in STD outgoing voice calls outside the calling circle\n",
    "- total_rech_amt_6: Total recharge amount in June\n",
    "- roam_og_mou_8:Minutes of outgoing voice calls in roaming\n",
    "- vol_3g_mb_7: Mobile internet usage 3G data volume in MB for \n",
    "- monthly_3g_6: Service schemes with validity equivalent to a month for 3G in June"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311ebb4",
   "metadata": {},
   "source": [
    "#### 5.2 Model 2 Development without PCA for all the customers for submission on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1edee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>84.34</td>\n",
       "      <td>84.85</td>\n",
       "      <td>83.82</td>\n",
       "      <td>83.98</td>\n",
       "      <td>84.85</td>\n",
       "      <td>84.85</td>\n",
       "      <td>16.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>92.91</td>\n",
       "      <td>99.86</td>\n",
       "      <td>85.95</td>\n",
       "      <td>87.67</td>\n",
       "      <td>99.86</td>\n",
       "      <td>99.86</td>\n",
       "      <td>14.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>92.67</td>\n",
       "      <td>93.20</td>\n",
       "      <td>92.14</td>\n",
       "      <td>92.23</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.20</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>94.37</td>\n",
       "      <td>94.84</td>\n",
       "      <td>93.89</td>\n",
       "      <td>93.95</td>\n",
       "      <td>94.84</td>\n",
       "      <td>94.84</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>99.95</td>\n",
       "      <td>99.94</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.94</td>\n",
       "      <td>99.94</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                                        \n",
       "Logistic Regression     84.34        84.85        83.82      83.98   84.85   \n",
       "KNN                     92.91        99.86        85.95      87.67   99.86   \n",
       "Decision Tree          100.00       100.00       100.00     100.00  100.00   \n",
       "Random Forest          100.00       100.00       100.00     100.00  100.00   \n",
       "Ada Boost               92.67        93.20        92.14      92.23   93.20   \n",
       "GradientBoosting        94.37        94.84        93.89      93.95   94.84   \n",
       "XGBoost                 99.95        99.94        99.96      99.96   99.94   \n",
       "\n",
       "                     True Positive rate  False Positive rate  \n",
       "Model                                                         \n",
       "Logistic Regression               84.85                16.18  \n",
       "KNN                               99.86                14.05  \n",
       "Decision Tree                    100.00                 0.00  \n",
       "Random Forest                    100.00                 0.00  \n",
       "Ada Boost                         93.20                 7.86  \n",
       "GradientBoosting                  94.84                 6.11  \n",
       "XGBoost                           99.94                 0.04  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "output= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "classifiers = {'Logistic Regression': LogisticRegression(),\n",
    "                'KNN': KNeighborsClassifier(),\n",
    "                'Decision Tree':DecisionTreeClassifier(),\n",
    "                'Random Forest': RandomForestClassifier(),\n",
    "                'Ada Boost':AdaBoostClassifier(),\n",
    "                'GradientBoosting':GradientBoostingClassifier(),\n",
    "                'XGBoost':xgb.XGBClassifier()}\n",
    "for model,classifier in classifiers.items():\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train_smo, y_train_smo)\n",
    "    output=output.append(Metrics(X_train_smo, y_train_smo,classifier,model),ignore_index=True)\n",
    "output.set_index(\"Model\", inplace=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a9a25",
   "metadata": {},
   "source": [
    "#### 5.2 Model Development with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0ee6749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "32720503",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca=pca.fit_transform(X_train)\n",
    "X_test_pca=pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cce8c518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0,len(pca.explained_variance_ratio_)),np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2d5286cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At around 60 features around 90% of variance in data is explained, thus using n=60\n",
    "pca=PCA(n_components=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbcbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca=pca.fit_transform(X_train)\n",
    "X_test_pca=pca.transform(X_test)\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output_pca= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "classifiers = {'Logistic Regression': LogisticRegression(),\n",
    "               'KNN': KNeighborsClassifier(),\n",
    "                'Decision Tree':DecisionTreeClassifier(),\n",
    "                'Random Forest': RandomForestClassifier(),\n",
    "                'Ada Boost':AdaBoostClassifier(),\n",
    "                'GradientBoosting':GradientBoostingClassifier(),\n",
    "                'XGBoost':xgb.XGBClassifier()}\n",
    "for model,classifier in classifiers.items():\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train_pca, y_train)\n",
    "    output_pca=output_pca.append(Metrics(X_train_pca,y_train,classifier,model),ignore_index=True)\n",
    "output_pca.set_index(\"Model\", inplace=True)\n",
    "output_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea168b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output_pca= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "classifiers = {'Logistic Regression': LogisticRegression(),\n",
    "               'KNN': KNeighborsClassifier(),\n",
    "                'Decision Tree':DecisionTreeClassifier(),\n",
    "                'Random Forest': RandomForestClassifier(),\n",
    "                'Ada Boost':AdaBoostClassifier(),\n",
    "                'GradientBoosting':GradientBoostingClassifier(),\n",
    "                'XGBoost':xgb.XGBClassifier()}\n",
    "for model,classifier in classifiers.items():\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train_pca, y_train)\n",
    "    output_pca=output_pca.append(Metrics(X_test_pca,y_test,classifier,model),ignore_index=True)\n",
    "output_pca.set_index(\"Model\", inplace=True)\n",
    "output_pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression\t84.34\t84.85\t83.82\t83.98\t84.85\t84.85\t16.18\n",
    "KNN\t92.91\t99.86\t85.95\t87.67\t99.86\t99.86\t14.05\n",
    "Decision Tree\t100.00\t100.00\t100.00\t100.00\t100.00\t100.00\t0.00\n",
    "Random Forest\t100.00\t100.00\t100.00\t100.00\t100.00\t100.00\t0.00\n",
    "Ada Boost\t92.67\t93.20\t92.14\t92.23\t93.20\t93.20\t7.86\n",
    "GradientBoosting\t94.37\t94.84\t93.89\t93.95\t94.84\t94.84\t6.11\n",
    "XGBoost\t99.95\t99.94\t99.96\t99.96\t99.94\t99.94\t0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521ee4df",
   "metadata": {},
   "source": [
    "As seen above PCA is not helping much in increasing the Recall for the case even when 99% of variance is expained through PCA, may be because there is very less correlation among data or because of non linear data. Further, execution time with PCA is more compared with without PCA. Therefore we will continue with further treatment without PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f63614",
   "metadata": {},
   "source": [
    "#### 5.3 Model Development with HyperParamter Tunning (HPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef508c",
   "metadata": {},
   "source": [
    "#### 5.3.1 Decision Tree Classifier  with HPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9264f86",
   "metadata": {},
   "source": [
    "Lets deploy  GridSearch CV with startifiedCV in order to tune Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9227395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep scoring as recall as want all the churn cases to be predicted accuartely.\n",
    "#folds\n",
    "cv=StratifiedKFold(n_splits=5,  shuffle=False, random_state=None)\n",
    "params={'max_depth': [8,10,12],\n",
    "       'min_samples_split':[8,10,12],\n",
    "       'min_samples_leaf':[2,5,10]}\n",
    "model_cv=GridSearchCV(estimator=DecisionTreeClassifier(),\n",
    "                           scoring='accuracy',\n",
    "                           param_grid=params,\n",
    "                           cv=cv,\n",
    "                           verbose=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bccbc078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Wall time: 2min 12s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [8, 10, 12],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [8, 10, 12]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [8, 10, 12],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [8, 10, 12]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [8, 10, 12],\n",
       "                         'min_samples_leaf': [2, 5, 10],\n",
       "                         'min_samples_split': [8, 10, 12]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a762dc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "87bdb791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>94.65</td>\n",
       "      <td>67.43</td>\n",
       "      <td>97.74</td>\n",
       "      <td>77.18</td>\n",
       "      <td>67.43</td>\n",
       "      <td>67.43</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                                  \n",
       "Decision Tree     94.65        67.43        97.74      77.18   67.43   \n",
       "\n",
       "               True Positive rate  False Positive rate  \n",
       "Model                                                   \n",
       "Decision Tree               67.43                 2.26  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=model_cv.best_estimator_\n",
    "tree.fit(X_train, y_train)\n",
    "metrics_dt= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics_dt=metrics_dt.append(Metrics(X_train, y_train,tree, 'Decision Tree'),ignore_index=True)\n",
    "metrics_dt.set_index(\"Model\", inplace=True)\n",
    "metrics_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e717915",
   "metadata": {},
   "source": [
    "#### 5.3.2 RandomForestClassifier with HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "97a89ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep scoring as recall as want all the churn cases to be predicted accuartely.\n",
    "#folds\n",
    "cv=StratifiedKFold(n_splits=5,  shuffle=False, random_state=None)\n",
    "params={'n_estimators':[200],#Actual values used [100,150]\n",
    "        'max_depth': [15],#[8,10,12]\n",
    "       'min_samples_split':[15],#[12,15,20]\n",
    "       'min_samples_leaf':[2]}#[2,5,10]\n",
    "model_cv=GridSearchCV(estimator=RandomForestClassifier(oob_score=True),\n",
    "                           scoring='accuracy',\n",
    "                           param_grid=params,\n",
    "                           cv=cv,\n",
    "                           verbose=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cb6fdedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(oob_score=True), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [15], &#x27;min_samples_leaf&#x27;: [2],\n",
       "                         &#x27;min_samples_split&#x27;: [15], &#x27;n_estimators&#x27;: [200]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(oob_score=True), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [15], &#x27;min_samples_leaf&#x27;: [2],\n",
       "                         &#x27;min_samples_split&#x27;: [15], &#x27;n_estimators&#x27;: [200]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(oob_score=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(oob_score=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(oob_score=True), n_jobs=-1,\n",
       "             param_grid={'max_depth': [15], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [15], 'n_estimators': [200]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b11ef159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 15,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6cbad0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>95.77</td>\n",
       "      <td>69.17</td>\n",
       "      <td>98.79</td>\n",
       "      <td>86.67</td>\n",
       "      <td>69.17</td>\n",
       "      <td>69.17</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                                  \n",
       "Random Forest     95.77        69.17        98.79      86.67   69.17   \n",
       "\n",
       "               True Positive rate  False Positive rate  \n",
       "Model                                                   \n",
       "Random Forest               69.17                 1.21  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=model_cv.best_estimator_\n",
    "rf.fit(X_train, y_train)\n",
    "metrics_rf= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics_rf=metrics_rf.append(Metrics(X_train, y_train,rf, 'Random Forest'),ignore_index=True)\n",
    "metrics_rf.set_index(\"Model\", inplace=True)\n",
    "metrics_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3578b211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420134573351048"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73115e78",
   "metadata": {},
   "source": [
    "#### 5.3.3 GradientBoostingClassifier with HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dbe19457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>99.82</td>\n",
       "      <td>98.58</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.62</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.58</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                                      \n",
       "Gradient Boosting     99.82        98.58        99.96      99.62   98.58   \n",
       "\n",
       "                   True Positive rate  False Positive rate  \n",
       "Model                                                       \n",
       "Gradient Boosting               98.58                 0.04  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gb=GradientBoostingClassifier(n_estimators=150,learning_rate=0.1,max_depth=10)\n",
    "gb.fit(X_train, y_train)\n",
    "metrics_gb= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics_gb=metrics_gb.append(Metrics(X_train, y_train,gb, 'Gradient Boosting'),ignore_index=True)\n",
    "metrics_gb.set_index(\"Model\", inplace=True)\n",
    "metrics_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a128c",
   "metadata": {},
   "source": [
    "#### 5.3.4 XGBoosting with HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fe6919ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgboost=xgb.XGBClassifier(n_estimators=150,learning_rate=0.05,max_depth=10)\n",
    "xgboost.fit(X_train, y_train)\n",
    "metrics_xgb= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "00234433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>98.26</td>\n",
       "      <td>91.77</td>\n",
       "      <td>99.0</td>\n",
       "      <td>91.22</td>\n",
       "      <td>91.77</td>\n",
       "      <td>91.77</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                               \n",
       "XGBoosting     98.26        91.77         99.0      91.22   91.77   \n",
       "\n",
       "            True Positive rate  False Positive rate  \n",
       "Model                                                \n",
       "XGBoosting               91.77                  1.0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_xgb=metrics_xgb.append(Metrics(X_train, y_train,xgboost, 'XGBoosting'),ignore_index=True)\n",
    "metrics_xgb.set_index(\"Model\", inplace=True)\n",
    "metrics_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5b33d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.93</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                               \n",
       "XGBoosting     99.99        100.0        99.99      99.93   100.0   \n",
       "\n",
       "            True Positive rate  False Positive rate  \n",
       "Model                                                \n",
       "XGBoosting               100.0                 0.01  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgboost=xgb.XGBClassifier(n_estimators=300,learning_rate=0.1,max_depth=10,reg_alpha=0.2,reg_lambda=0.2)\n",
    "xgboost.fit(X_train, y_train)\n",
    "metrics_xgb= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics_xgb=metrics_xgb.append(Metrics(X_train, y_train,xgboost, 'XGBoosting'),ignore_index=True)\n",
    "metrics_xgb.set_index(\"Model\", inplace=True)\n",
    "metrics_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "181aea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics using various Models after HPT are as under: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>94.65</td>\n",
       "      <td>67.43</td>\n",
       "      <td>97.74</td>\n",
       "      <td>77.18</td>\n",
       "      <td>67.43</td>\n",
       "      <td>67.43</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>95.77</td>\n",
       "      <td>69.17</td>\n",
       "      <td>98.79</td>\n",
       "      <td>86.67</td>\n",
       "      <td>69.17</td>\n",
       "      <td>69.17</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>99.82</td>\n",
       "      <td>98.58</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.62</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.58</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.93</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Sensitivity  Specificity  Precision  Recall  \\\n",
       "Model                                                                      \n",
       "Decision Tree         94.65        67.43        97.74      77.18   67.43   \n",
       "Random Forest         95.77        69.17        98.79      86.67   69.17   \n",
       "Gradient Boosting     99.82        98.58        99.96      99.62   98.58   \n",
       "XGBoosting            99.99       100.00        99.99      99.93  100.00   \n",
       "\n",
       "                   True Positive rate  False Positive rate  \n",
       "Model                                                       \n",
       "Decision Tree                   67.43                 2.26  \n",
       "Random Forest                   69.17                 1.21  \n",
       "Gradient Boosting               98.58                 0.04  \n",
       "XGBoosting                     100.00                 0.01  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics=pd.concat([metrics_dt,metrics_rf], axis=0)\n",
    "final_metrics=pd.concat([final_metrics,metrics_gb], axis=0)\n",
    "final_metrics=pd.concat([final_metrics,metrics_xgb], axis=0)\n",
    "print('Metrics using various Models after HPT are as under: ')\n",
    "final_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a2b49",
   "metadata": {},
   "source": [
    "As seen from above best model is XGBoost so lets evaluate model with test data on XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "33b82aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positive rate</th>\n",
       "      <th>False Positive rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Test</th>\n",
       "      <td>94.01</td>\n",
       "      <td>64.66</td>\n",
       "      <td>97.35</td>\n",
       "      <td>73.45</td>\n",
       "      <td>64.66</td>\n",
       "      <td>64.66</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Test</th>\n",
       "      <td>94.46</td>\n",
       "      <td>61.69</td>\n",
       "      <td>98.18</td>\n",
       "      <td>79.39</td>\n",
       "      <td>61.69</td>\n",
       "      <td>61.69</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradiesnt Boosting Test</th>\n",
       "      <td>94.21</td>\n",
       "      <td>65.77</td>\n",
       "      <td>97.44</td>\n",
       "      <td>74.44</td>\n",
       "      <td>65.77</td>\n",
       "      <td>65.77</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting Test</th>\n",
       "      <td>94.58</td>\n",
       "      <td>65.51</td>\n",
       "      <td>97.88</td>\n",
       "      <td>77.83</td>\n",
       "      <td>65.51</td>\n",
       "      <td>65.51</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Sensitivity  Specificity  Precision  \\\n",
       "Model                                                                    \n",
       "Decision Tree Test          94.01        64.66        97.35      73.45   \n",
       "Random Forest Test          94.46        61.69        98.18      79.39   \n",
       "Gradiesnt Boosting Test     94.21        65.77        97.44      74.44   \n",
       "XGBoosting Test             94.58        65.51        97.88      77.83   \n",
       "\n",
       "                         Recall  True Positive rate  False Positive rate  \n",
       "Model                                                                     \n",
       "Decision Tree Test        64.66               64.66                 2.65  \n",
       "Random Forest Test        61.69               61.69                 1.82  \n",
       "Gradiesnt Boosting Test   65.77               65.77                 2.56  \n",
       "XGBoosting Test           65.51               65.51                 2.12  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_xgb_test= pd.DataFrame(columns=['Model','Accuracy','Sensitivity','Specificity','Precision','Recall',\n",
    "                                 'True Positive rate','False Positive rate'])\n",
    "metrics_xgb_test=metrics_xgb_test.append(Metrics(X_test, y_test,tree, 'Decision Tree Test'),ignore_index=True)\n",
    "metrics_xgb_test=metrics_xgb_test.append(Metrics(X_test, y_test,rf, 'Random Forest Test'),ignore_index=True)\n",
    "metrics_xgb_test=metrics_xgb_test.append(Metrics(X_test, y_test,gb, 'Gradiesnt Boosting Test'),ignore_index=True)\n",
    "metrics_xgb_test=metrics_xgb_test.append(Metrics(X_test, y_test,xgboost, 'XGBoosting Test'),ignore_index=True)\n",
    "\n",
    "metrics_xgb_test.set_index(\"Model\", inplace=True)\n",
    "metrics_xgb_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326fc2f",
   "metadata": {},
   "source": [
    "- Max Recall value on test data is around 65.77% which means model is able to correctly predict only 65.77% of actual churn cases.\n",
    "- This model cannot be deployed for detecting churn customers in real world.\n",
    "- However primary aim was to have higher accuary in prediction for overall data for submission in Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e9fe8",
   "metadata": {},
   "source": [
    "## 6. Submission in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "245dd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7cdf69fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       churn_probability\n",
       "id                      \n",
       "69999                  0\n",
       "70000                  0\n",
       "70001                  1\n",
       "70002                  0\n",
       "70003                  0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Submission in Kaggle\n",
    "submission=pd.DataFrame({'id':test_df.id, 'churn_probability':y_test_pred})\n",
    "submission=submission.set_index('id')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "93b54f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Submission2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8767f",
   "metadata": {},
   "source": [
    "## 7. Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab1b87",
   "metadata": {},
   "source": [
    "##### 7.1 Model 1: For interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c66c91",
   "metadata": {},
   "source": [
    "1. Maximum factors which are effecting churn are for month August.\n",
    "2. Churn rate is high when Total incoming  and ougoing minutes for voice calls in August is lower. Thus if no of incoming and outgoing calls are decreasing for a particular customer there is high change he may be switching to another network.\n",
    "3. Lower Service schemes with validity equivalent to a month for 3G in August also indicates higher probability of churn. If network condition in a place is good, customers will use data early thus there will more no. of recharges and thus less chances of churn, however if network is poor then data will not be consumed and thus no. of monthly recharges will be less, leading to churn. \n",
    "4. If incoming calls are high and outgoing calls are less then customer may be finding the services very costly and may switch to network where incoming and outgoing services are in less/reasonable according to him/her."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad287b61",
   "metadata": {},
   "source": [
    "##### 7.2 Model 2: For purpose of accurate prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b623d",
   "metadata": {},
   "source": [
    "Final Model for Submission is XGBoosting model with test accuracy of 94.58%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f65bd0",
   "metadata": {},
   "source": [
    "- Created by- @Rohitcnith & @GiridharTarare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
